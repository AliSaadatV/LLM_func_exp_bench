{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "00ebb274",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any, Optional, Literal, Sequence\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from pydantic import BaseModel, Field\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e198a97c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len = 1709\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#Variation</th>\n",
              "      <th>ClinVar Variation Id</th>\n",
              "      <th>Allele Registry Id</th>\n",
              "      <th>HGVS Expressions</th>\n",
              "      <th>HGNC Gene Symbol</th>\n",
              "      <th>Disease</th>\n",
              "      <th>Mondo Id</th>\n",
              "      <th>Mode of Inheritance</th>\n",
              "      <th>Assertion</th>\n",
              "      <th>Applied Evidence Codes (Met)</th>\n",
              "      <th>...</th>\n",
              "      <th>PS3_abstracts</th>\n",
              "      <th>BS3_abstracts</th>\n",
              "      <th>PS3_urls</th>\n",
              "      <th>BS3_urls</th>\n",
              "      <th>PS3_urls_downloaded</th>\n",
              "      <th>BS3_urls_downloaded</th>\n",
              "      <th>PS3_level</th>\n",
              "      <th>BS3_level</th>\n",
              "      <th>PS3_comments</th>\n",
              "      <th>BS3_comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NM_000277.2(PAH):c.1A&gt;G (p.Met1Val)</td>\n",
              "      <td>586</td>\n",
              "      <td>CA114360</td>\n",
              "      <td>NM_000277.2:c.1A&gt;G, NC_000012.12:g.102917130T&gt;...</td>\n",
              "      <td>PAH</td>\n",
              "      <td>phenylketonuria</td>\n",
              "      <td>MONDO:0009861</td>\n",
              "      <td>Autosomal recessive inheritance</td>\n",
              "      <td>Pathogenic</td>\n",
              "      <td>PM3, PP4_Moderate, PM2, PS3</td>\n",
              "      <td>...</td>\n",
              "      <td>Mutations in the human phenylalanine hydroxyla...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PS3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;3%</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NM_000277.2(PAH):c.472C&gt;T (p.Arg158Trp)</td>\n",
              "      <td>102693</td>\n",
              "      <td>CA229570</td>\n",
              "      <td>NM_000277.2:c.472C&gt;T, NC_000012.12:g.102866633...</td>\n",
              "      <td>PAH</td>\n",
              "      <td>phenylketonuria</td>\n",
              "      <td>MONDO:0009861</td>\n",
              "      <td>Autosomal recessive inheritance</td>\n",
              "      <td>Pathogenic</td>\n",
              "      <td>PP4_Moderate, PM2, PP3, PS3, PM3_Strong</td>\n",
              "      <td>...</td>\n",
              "      <td>To investigate the mutations of the phenylalan...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>;;;;http://europepmc.org/backend/ptpmcrender.f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://europepmc.org/backend/ptpmcrender.fcgi?...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PS3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2% mutant enzyme activity in BioPKU</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NM_000277.2(PAH):c.533A&gt;G (p.Glu178Gly)</td>\n",
              "      <td>92746</td>\n",
              "      <td>CA273110</td>\n",
              "      <td>NM_000277.2:c.533A&gt;G, NC_000012.12:g.102855309...</td>\n",
              "      <td>PAH</td>\n",
              "      <td>phenylketonuria</td>\n",
              "      <td>MONDO:0009861</td>\n",
              "      <td>Autosomal recessive inheritance</td>\n",
              "      <td>Pathogenic</td>\n",
              "      <td>PS3_Supporting, PP4_Moderate, PM2_Supporting, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>Mutations in the phenylalanine hydroxylase (PA...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PS3_supporting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Enzyme activity assay showed 39% residual phen...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NM_000277.2(PAH):c.963C&gt;T (p.Leu321=)</td>\n",
              "      <td>102911</td>\n",
              "      <td>CA229873</td>\n",
              "      <td>NM_000277.2:c.963C&gt;T, NC_000012.12:g.102846901...</td>\n",
              "      <td>PAH</td>\n",
              "      <td>phenylketonuria</td>\n",
              "      <td>MONDO:0009861</td>\n",
              "      <td>Autosomal recessive inheritance</td>\n",
              "      <td>Benign</td>\n",
              "      <td>BS2, BS3_Supporting, BS1, BP7</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BS3_supporting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cDNA method demonstrates 98% and intinic syste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NM_000277.2(PAH):c.194T&gt;C (p.Ile65Thr)</td>\n",
              "      <td>636</td>\n",
              "      <td>CA251544</td>\n",
              "      <td>NM_000277.2:c.194T&gt;C, NC_000012.12:g.102894893...</td>\n",
              "      <td>PAH</td>\n",
              "      <td>phenylketonuria</td>\n",
              "      <td>MONDO:0009861</td>\n",
              "      <td>Autosomal recessive inheritance</td>\n",
              "      <td>Pathogenic</td>\n",
              "      <td>PP4_Moderate, PP3, PM3_Very Strong, PS3</td>\n",
              "      <td>...</td>\n",
              "      <td>Mutations at the phenylalanine hydroxylase (PA...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PS3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25% mutant enzyme activity in COS cells as com...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                #Variation ClinVar Variation Id  \\\n",
              "0      NM_000277.2(PAH):c.1A>G (p.Met1Val)                  586   \n",
              "1  NM_000277.2(PAH):c.472C>T (p.Arg158Trp)               102693   \n",
              "2  NM_000277.2(PAH):c.533A>G (p.Glu178Gly)                92746   \n",
              "3    NM_000277.2(PAH):c.963C>T (p.Leu321=)               102911   \n",
              "4   NM_000277.2(PAH):c.194T>C (p.Ile65Thr)                  636   \n",
              "\n",
              "  Allele Registry Id                                   HGVS Expressions  \\\n",
              "0           CA114360  NM_000277.2:c.1A>G, NC_000012.12:g.102917130T>...   \n",
              "1           CA229570  NM_000277.2:c.472C>T, NC_000012.12:g.102866633...   \n",
              "2           CA273110  NM_000277.2:c.533A>G, NC_000012.12:g.102855309...   \n",
              "3           CA229873  NM_000277.2:c.963C>T, NC_000012.12:g.102846901...   \n",
              "4           CA251544  NM_000277.2:c.194T>C, NC_000012.12:g.102894893...   \n",
              "\n",
              "  HGNC Gene Symbol          Disease       Mondo Id  \\\n",
              "0              PAH  phenylketonuria  MONDO:0009861   \n",
              "1              PAH  phenylketonuria  MONDO:0009861   \n",
              "2              PAH  phenylketonuria  MONDO:0009861   \n",
              "3              PAH  phenylketonuria  MONDO:0009861   \n",
              "4              PAH  phenylketonuria  MONDO:0009861   \n",
              "\n",
              "               Mode of Inheritance   Assertion  \\\n",
              "0  Autosomal recessive inheritance  Pathogenic   \n",
              "1  Autosomal recessive inheritance  Pathogenic   \n",
              "2  Autosomal recessive inheritance  Pathogenic   \n",
              "3  Autosomal recessive inheritance      Benign   \n",
              "4  Autosomal recessive inheritance  Pathogenic   \n",
              "\n",
              "                        Applied Evidence Codes (Met)  ...  \\\n",
              "0                        PM3, PP4_Moderate, PM2, PS3  ...   \n",
              "1            PP4_Moderate, PM2, PP3, PS3, PM3_Strong  ...   \n",
              "2  PS3_Supporting, PP4_Moderate, PM2_Supporting, ...  ...   \n",
              "3                      BS2, BS3_Supporting, BS1, BP7  ...   \n",
              "4            PP4_Moderate, PP3, PM3_Very Strong, PS3  ...   \n",
              "\n",
              "                                       PS3_abstracts BS3_abstracts  \\\n",
              "0  Mutations in the human phenylalanine hydroxyla...           NaN   \n",
              "1  To investigate the mutations of the phenylalan...           NaN   \n",
              "2  Mutations in the phenylalanine hydroxylase (PA...           NaN   \n",
              "3                                                NaN           NaN   \n",
              "4  Mutations at the phenylalanine hydroxylase (PA...           NaN   \n",
              "\n",
              "                                            PS3_urls BS3_urls  \\\n",
              "0                                                NaN      NaN   \n",
              "1  ;;;;http://europepmc.org/backend/ptpmcrender.f...      NaN   \n",
              "2                                                NaN      NaN   \n",
              "3                                                NaN      NaN   \n",
              "4                                                NaN      NaN   \n",
              "\n",
              "                                 PS3_urls_downloaded BS3_urls_downloaded  \\\n",
              "0                                                NaN                 NaN   \n",
              "1  http://europepmc.org/backend/ptpmcrender.fcgi?...                 NaN   \n",
              "2                                                NaN                 NaN   \n",
              "3                                                NaN                 NaN   \n",
              "4                                                NaN                 NaN   \n",
              "\n",
              "        PS3_level       BS3_level  \\\n",
              "0             PS3             NaN   \n",
              "1             PS3             NaN   \n",
              "2  PS3_supporting             NaN   \n",
              "3             NaN  BS3_supporting   \n",
              "4             PS3             NaN   \n",
              "\n",
              "                                        PS3_comments  \\\n",
              "0                                                <3%   \n",
              "1                2% mutant enzyme activity in BioPKU   \n",
              "2  Enzyme activity assay showed 39% residual phen...   \n",
              "3                                                NaN   \n",
              "4  25% mutant enzyme activity in COS cells as com...   \n",
              "\n",
              "                                        BS3_comments  \n",
              "0                                                NaN  \n",
              "1                                                NaN  \n",
              "2                                                NaN  \n",
              "3  cDNA method demonstrates 98% and intinic syste...  \n",
              "4                                                NaN  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps3_bs3_df = pd.read_csv(\"../data/ps3_bs3_df_processed.csv\")\n",
        "print(f\"len = {len(ps3_bs3_df)}\")\n",
        "ps3_bs3_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e6d0943f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total rows before drop: 1087\n",
            "rows with missing abstracts: 33\n",
            "total rows after drop: 1054\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pmid</th>\n",
              "      <th>abstract</th>\n",
              "      <th>evidence</th>\n",
              "      <th>functional_experiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9450897</td>\n",
              "      <td>Mutations in the human phenylalanine hydroxyla...</td>\n",
              "      <td>PS3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1307609</td>\n",
              "      <td>To investigate the mutations of the phenylalan...</td>\n",
              "      <td>PS3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10429004</td>\n",
              "      <td>OBJECTIVE: To examine the relationship of phen...</td>\n",
              "      <td>PS3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9634518</td>\n",
              "      <td>Phenylketonuria (PKU) and mild hyperphenylalan...</td>\n",
              "      <td>PS3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17935162</td>\n",
              "      <td>Mutations in the phenylalanine hydroxylase (PA...</td>\n",
              "      <td>PS3_supporting</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       pmid                                           abstract  \\\n",
              "0   9450897  Mutations in the human phenylalanine hydroxyla...   \n",
              "1   1307609  To investigate the mutations of the phenylalan...   \n",
              "2  10429004  OBJECTIVE: To examine the relationship of phen...   \n",
              "3   9634518  Phenylketonuria (PKU) and mild hyperphenylalan...   \n",
              "4  17935162  Mutations in the phenylalanine hydroxylase (PA...   \n",
              "\n",
              "         evidence  functional_experiment  \n",
              "0             PS3                      1  \n",
              "1             PS3                      1  \n",
              "2             PS3                      1  \n",
              "3             PS3                      1  \n",
              "4  PS3_supporting                      1  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def _choose(row, ps3_col, bs3_col):\n",
        "    return row[ps3_col] if pd.notna(row[\"PS3_level\"]) else row[bs3_col]\n",
        "\n",
        "def _split_multi(val):\n",
        "    if pd.isna(val):\n",
        "        return []\n",
        "    return [x.strip() for x in str(val).split(\";;\") if x.strip()]\n",
        "\n",
        "# pick source columns based on PS3_level existence\n",
        "tmp = ps3_bs3_df.copy()\n",
        "tmp[\"pmids_src\"] = tmp.apply(_choose, axis=1, ps3_col=\"PS3_pmids\", bs3_col=\"BS3_pmids\")\n",
        "tmp[\"abstracts_src\"] = tmp.apply(_choose, axis=1, ps3_col=\"PS3_abstracts\", bs3_col=\"BS3_abstracts\")\n",
        "tmp[\"evidence\"] = tmp.apply(\n",
        "    lambda r: r[\"PS3_level\"] if pd.notna(r[\"PS3_level\"]) else r[\"BS3_level\"],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# split pmids/abstracts\n",
        "tmp[\"pmids_list\"] = tmp[\"pmids_src\"].apply(_split_multi)\n",
        "tmp[\"abstracts_list\"] = tmp[\"abstracts_src\"].apply(_split_multi)\n",
        "\n",
        "# explode and align pmids/abstracts; keep paired by position\n",
        "def _explode_row(row):\n",
        "    n = max(len(row[\"pmids_list\"]), len(row[\"abstracts_list\"]))\n",
        "    pmids = row[\"pmids_list\"] + [np.nan] * (n - len(row[\"pmids_list\"]))\n",
        "    abstracts = row[\"abstracts_list\"] + [np.nan] * (n - len(row[\"abstracts_list\"]))\n",
        "    return pd.DataFrame({\n",
        "        \"pmid\": pmids,\n",
        "        \"abstract\": abstracts,\n",
        "        \"evidence\": [row[\"evidence\"]] * n,\n",
        "    })\n",
        "\n",
        "ps3_bs3_abstracts_df = (\n",
        "    pd.concat([_explode_row(r) for _, r in tmp.iterrows()], ignore_index=True)\n",
        "    .dropna(subset=[\"pmid\", \"abstract\"], how=\"all\")\n",
        ")\n",
        "\n",
        "ps3_bs3_abstracts_df = ps3_bs3_abstracts_df.drop_duplicates(subset=\"pmid\").reset_index(drop=True)\n",
        "\n",
        "missing_abstracts = ps3_bs3_abstracts_df[\"abstract\"].isna() | (ps3_bs3_abstracts_df[\"abstract\"].astype(str).str.strip() == \"\")\n",
        "print(\"total rows before drop:\", len(ps3_bs3_abstracts_df))\n",
        "print(\"rows with missing abstracts:\", missing_abstracts.sum())\n",
        "\n",
        "ps3_bs3_abstracts_df = ps3_bs3_abstracts_df[~missing_abstracts].reset_index(drop=True)\n",
        "print(\"total rows after drop:\", len(ps3_bs3_abstracts_df))\n",
        "\n",
        "ps3_bs3_abstracts_df['functional_experiment'] = 1\n",
        "ps3_bs3_abstracts_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c2dcd155",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len ps3_bs3_abstracts_df: 529\n"
          ]
        }
      ],
      "source": [
        "# keep only pmids that have pdf papers in ../res/pdfs\n",
        "pdf_dir = \"../res/pdfs\"\n",
        "available_pmids = set(os.path.splitext(f)[0] for f in os.listdir(pdf_dir) if f.endswith(\".pdf\"))\n",
        "ps3_bs3_abstracts_df = ps3_bs3_abstracts_df[ps3_bs3_abstracts_df[\"pmid\"].astype(str).isin(available_pmids)].reset_index(drop=True)\n",
        "print(\"len ps3_bs3_abstracts_df:\", len(ps3_bs3_abstracts_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0df26aea",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "evidence\n",
              "PS3_supporting    214\n",
              "PS3               147\n",
              "PS3_moderate      110\n",
              "BS3_supporting     23\n",
              "BS3                17\n",
              "PS3_Moderate        5\n",
              "PS3_VeryStrong      5\n",
              "PS3_Strong          3\n",
              "BS3_moderate        2\n",
              "PS3_Supporting      2\n",
              "PS3_P               1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count evidence types\n",
        "ps3_bs3_abstracts_df['evidence'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ef03f07b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "evidence\n",
              "PS3_supporting    217\n",
              "PS3_strong        150\n",
              "PS3_moderate      115\n",
              "BS3_supporting     23\n",
              "BS3_strong         17\n",
              "PS3_verystrong      5\n",
              "BS3_moderate        2\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# rename PS3_P  to PS3_supporting, PS3 to PS3_strong,  BS3 to BS3_strong, and all the things after _ should be lowercase\n",
        "ps3_bs3_abstracts_df['evidence'] = ps3_bs3_abstracts_df['evidence'].replace({\n",
        "    'PS3_P': 'PS3_supporting',\n",
        "    'PS3': 'PS3_strong',\n",
        "    'BS3': 'BS3_strong',\n",
        "    'PS3_Moderate': 'PS3_moderate',\n",
        "    'PS3_VeryStrong': 'PS3_verystrong',\n",
        "    'PS3_Strong': 'PS3_strong',\n",
        "    'PS3_Supporting': 'PS3_supporting'\n",
        "})\n",
        "ps3_bs3_abstracts_df['evidence'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6f18f75c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len = 1478\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pmid</th>\n",
              "      <th>abstract</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9450897</td>\n",
              "      <td>Mutations in the human phenylalanine hydroxyla...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2574002</td>\n",
              "      <td>We analyzed DNA from nine French-Canadian prob...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9012412</td>\n",
              "      <td>Using mutation and haplotype analysis, we have...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8268925</td>\n",
              "      <td>Hyperphenylalaninemia due to a deficiency of h...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23430918</td>\n",
              "      <td>Prospectively enrolled phenylketonuria patient...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       pmid                                           abstract full_text\n",
              "0   9450897  Mutations in the human phenylalanine hydroxyla...       NaN\n",
              "1   2574002  We analyzed DNA from nine French-Canadian prob...       NaN\n",
              "2   9012412  Using mutation and haplotype analysis, we have...       NaN\n",
              "3   8268925  Hyperphenylalaninemia due to a deficiency of h...       NaN\n",
              "4  23430918  Prospectively enrolled phenylketonuria patient...       NaN"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pubmed_df = pd.read_csv(\"../data/cgbench_pubmed_id_to_text.csv\")\n",
        "# remove PubMed: from pmid column\n",
        "pubmed_df[\"pmid\"] = pubmed_df[\"pmid\"].apply(lambda x: re.sub(r'^PubMed:\\s*', '', x))\n",
        "pubmed_df = pubmed_df.drop_duplicates(subset=\"pmid\").dropna(subset=\"abstract\").reset_index(drop=True)\n",
        "print(f\"len = {len(pubmed_df)}\")\n",
        "pubmed_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "79979eff",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pmid</th>\n",
              "      <th>abstract</th>\n",
              "      <th>evidence</th>\n",
              "      <th>functional_experiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37011710</td>\n",
              "      <td>The von Willebrand factor (VWF) is a multimeri...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27092720</td>\n",
              "      <td>Primary open angle glaucoma-associated mutatio...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15033936</td>\n",
              "      <td>Mutations in the gene GJB2, encoding the gap j...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12393175</td>\n",
              "      <td>A heteroplasmic T to C transition at nucleotid...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28814660</td>\n",
              "      <td>Cross-reactive immunological material-negative...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>35699829</td>\n",
              "      <td>Leber's hereditary optic neuropathy (LHON) is ...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>17612745</td>\n",
              "      <td>The clinical profile and prognosis of patients...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>15322508</td>\n",
              "      <td>There were an estimated 10 million new cases, ...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>20228067</td>\n",
              "      <td>Mutations in the COCH (coagulation factor C ho...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>30214072</td>\n",
              "      <td>To investigate immune tolerance induction with...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>529 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         pmid                                           abstract     evidence  \\\n",
              "0    37011710  The von Willebrand factor (VWF) is a multimeri...  non_PS3_BS3   \n",
              "1    27092720  Primary open angle glaucoma-associated mutatio...  non_PS3_BS3   \n",
              "2    15033936  Mutations in the gene GJB2, encoding the gap j...  non_PS3_BS3   \n",
              "3    12393175  A heteroplasmic T to C transition at nucleotid...  non_PS3_BS3   \n",
              "4    28814660  Cross-reactive immunological material-negative...  non_PS3_BS3   \n",
              "..        ...                                                ...          ...   \n",
              "524  35699829  Leber's hereditary optic neuropathy (LHON) is ...  non_PS3_BS3   \n",
              "525  17612745  The clinical profile and prognosis of patients...  non_PS3_BS3   \n",
              "526  15322508  There were an estimated 10 million new cases, ...  non_PS3_BS3   \n",
              "527  20228067  Mutations in the COCH (coagulation factor C ho...  non_PS3_BS3   \n",
              "528  30214072  To investigate immune tolerance induction with...  non_PS3_BS3   \n",
              "\n",
              "     functional_experiment  \n",
              "0                        0  \n",
              "1                        0  \n",
              "2                        0  \n",
              "3                        0  \n",
              "4                        0  \n",
              "..                     ...  \n",
              "524                      0  \n",
              "525                      0  \n",
              "526                      0  \n",
              "527                      0  \n",
              "528                      0  \n",
              "\n",
              "[529 rows x 4 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find rows in pubmed_df that do not match any pmid in PS3_pmids or BS3_pmids\n",
        "ps3_bs3_pmids = ps3_bs3_abstracts_df.pmid.tolist()\n",
        "non_ps3_bs3_abstracts_df = pubmed_df[~pubmed_df[\"pmid\"].isin(ps3_bs3_pmids)]\n",
        "# remove full_text column \n",
        "non_ps3_bs3_abstracts_df = non_ps3_bs3_abstracts_df.drop(columns=[\"full_text\"])\n",
        "\n",
        "non_ps3_bs3_abstracts_df['evidence'] = \"non_PS3_BS3\"\n",
        "non_ps3_bs3_abstracts_df['functional_experiment'] = 0\n",
        "\n",
        "# randomly select the same number of rows as ps3_bs3_abstracts_df\n",
        "non_ps3_bs3_abstracts_df = non_ps3_bs3_abstracts_df.sample(n=len(ps3_bs3_abstracts_df), random_state=42).reset_index(drop=True)\n",
        "non_ps3_bs3_abstracts_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c51ea124",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len all_abstracts_df: 1058\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pmid</th>\n",
              "      <th>abstract</th>\n",
              "      <th>evidence</th>\n",
              "      <th>functional_experiment</th>\n",
              "      <th>gpt-4o-mini_functional_experiment</th>\n",
              "      <th>gpt-4o-mini_evidence</th>\n",
              "      <th>o4-mini_functional_experiment</th>\n",
              "      <th>o4-mini_evidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9634518</td>\n",
              "      <td>Phenylketonuria (PKU) and mild hyperphenylalan...</td>\n",
              "      <td>PS3_strong</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3615198</td>\n",
              "      <td>Classical Phenylketonuria (PKU) is an autosoma...</td>\n",
              "      <td>PS3_strong</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15319459</td>\n",
              "      <td>Tetrahydrobiopterin (BH4)-responsive phenylala...</td>\n",
              "      <td>PS3_strong</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24401910</td>\n",
              "      <td>Phenylalanine hydroxylase (PAH) deficiency is ...</td>\n",
              "      <td>PS3_strong</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>29706350</td>\n",
              "      <td>Phosphatase and tensin homolog (PTEN) is a tum...</td>\n",
              "      <td>BS3_supporting</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       pmid                                           abstract  \\\n",
              "0   9634518  Phenylketonuria (PKU) and mild hyperphenylalan...   \n",
              "1   3615198  Classical Phenylketonuria (PKU) is an autosoma...   \n",
              "2  15319459  Tetrahydrobiopterin (BH4)-responsive phenylala...   \n",
              "3  24401910  Phenylalanine hydroxylase (PAH) deficiency is ...   \n",
              "4  29706350  Phosphatase and tensin homolog (PTEN) is a tum...   \n",
              "\n",
              "         evidence  functional_experiment  gpt-4o-mini_functional_experiment  \\\n",
              "0      PS3_strong                      1                                NaN   \n",
              "1      PS3_strong                      1                                NaN   \n",
              "2      PS3_strong                      1                                NaN   \n",
              "3      PS3_strong                      1                                NaN   \n",
              "4  BS3_supporting                      1                                NaN   \n",
              "\n",
              "   gpt-4o-mini_evidence  o4-mini_functional_experiment  o4-mini_evidence  \n",
              "0                   NaN                            NaN               NaN  \n",
              "1                   NaN                            NaN               NaN  \n",
              "2                   NaN                            NaN               NaN  \n",
              "3                   NaN                            NaN               NaN  \n",
              "4                   NaN                            NaN               NaN  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_abstracts_df = pd.concat([ps3_bs3_abstracts_df, non_ps3_bs3_abstracts_df], ignore_index=True)\n",
        "all_abstracts_df['gpt-4o-mini_functional_experiment'] = np.nan\n",
        "all_abstracts_df['gpt-4o-mini_evidence'] = np.nan\n",
        "\n",
        "all_abstracts_df['o4-mini_functional_experiment'] = np.nan\n",
        "all_abstracts_df['o4-mini_evidence'] = np.nan\n",
        "print(f'len all_abstracts_df: {len(all_abstracts_df)}')\n",
        "all_abstracts_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f90721d5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed 5 rows\n",
            "processed 10 rows\n",
            "processed 15 rows\n",
            "processed 20 rows\n",
            "processed 25 rows\n",
            "processed 30 rows\n",
            "processed 35 rows\n",
            "processed 40 rows\n",
            "processed 45 rows\n",
            "processed 50 rows\n",
            "processed 55 rows\n",
            "processed 60 rows\n",
            "processed 65 rows\n",
            "processed 70 rows\n",
            "processed 75 rows\n",
            "processed 80 rows\n",
            "processed 85 rows\n",
            "processed 90 rows\n",
            "processed 95 rows\n",
            "processed 100 rows\n",
            "processed 105 rows\n",
            "processed 110 rows\n",
            "processed 115 rows\n",
            "processed 120 rows\n",
            "processed 125 rows\n",
            "processed 130 rows\n",
            "processed 135 rows\n",
            "processed 140 rows\n",
            "processed 145 rows\n",
            "processed 150 rows\n",
            "processed 155 rows\n",
            "processed 160 rows\n",
            "processed 165 rows\n",
            "processed 170 rows\n",
            "processed 175 rows\n",
            "processed 180 rows\n",
            "processed 185 rows\n",
            "processed 190 rows\n",
            "processed 195 rows\n",
            "processed 200 rows\n",
            "processed 205 rows\n",
            "processed 210 rows\n",
            "processed 215 rows\n",
            "processed 220 rows\n",
            "processed 225 rows\n",
            "processed 230 rows\n",
            "processed 235 rows\n",
            "processed 240 rows\n",
            "processed 245 rows\n",
            "processed 250 rows\n",
            "processed 255 rows\n",
            "processed 260 rows\n",
            "processed 265 rows\n",
            "processed 270 rows\n",
            "processed 275 rows\n",
            "processed 280 rows\n",
            "processed 285 rows\n",
            "processed 290 rows\n",
            "processed 295 rows\n",
            "processed 300 rows\n",
            "processed 305 rows\n",
            "processed 310 rows\n",
            "processed 315 rows\n",
            "processed 320 rows\n",
            "processed 325 rows\n",
            "processed 330 rows\n",
            "processed 335 rows\n",
            "processed 340 rows\n",
            "processed 345 rows\n",
            "processed 350 rows\n",
            "processed 355 rows\n",
            "processed 360 rows\n",
            "processed 365 rows\n",
            "processed 370 rows\n",
            "processed 375 rows\n",
            "processed 380 rows\n",
            "processed 385 rows\n",
            "processed 390 rows\n",
            "processed 395 rows\n",
            "processed 400 rows\n",
            "processed 405 rows\n",
            "processed 410 rows\n",
            "processed 415 rows\n",
            "processed 420 rows\n",
            "processed 425 rows\n",
            "processed 430 rows\n",
            "processed 435 rows\n",
            "processed 440 rows\n",
            "processed 445 rows\n",
            "processed 450 rows\n",
            "processed 455 rows\n",
            "processed 460 rows\n",
            "processed 465 rows\n",
            "processed 470 rows\n",
            "processed 475 rows\n",
            "processed 480 rows\n",
            "processed 485 rows\n",
            "processed 490 rows\n",
            "processed 495 rows\n",
            "processed 500 rows\n",
            "processed 505 rows\n",
            "processed 510 rows\n",
            "processed 515 rows\n",
            "processed 520 rows\n",
            "processed 525 rows\n",
            "processed 530 rows\n",
            "processed 535 rows\n",
            "processed 540 rows\n",
            "processed 545 rows\n",
            "processed 550 rows\n",
            "processed 555 rows\n",
            "processed 560 rows\n",
            "processed 565 rows\n",
            "processed 570 rows\n",
            "processed 575 rows\n",
            "processed 580 rows\n",
            "processed 585 rows\n",
            "processed 590 rows\n",
            "processed 595 rows\n",
            "processed 600 rows\n",
            "processed 605 rows\n",
            "processed 610 rows\n",
            "processed 615 rows\n",
            "processed 620 rows\n",
            "processed 625 rows\n",
            "processed 630 rows\n",
            "processed 635 rows\n",
            "processed 640 rows\n",
            "processed 645 rows\n",
            "processed 650 rows\n",
            "processed 655 rows\n",
            "processed 660 rows\n",
            "processed 665 rows\n",
            "processed 670 rows\n",
            "processed 675 rows\n",
            "processed 680 rows\n",
            "processed 685 rows\n",
            "processed 690 rows\n",
            "processed 695 rows\n",
            "processed 700 rows\n",
            "processed 705 rows\n",
            "processed 710 rows\n",
            "processed 715 rows\n",
            "processed 720 rows\n",
            "processed 725 rows\n",
            "processed 730 rows\n",
            "processed 735 rows\n",
            "processed 740 rows\n",
            "processed 745 rows\n",
            "processed 750 rows\n",
            "processed 755 rows\n",
            "processed 760 rows\n",
            "processed 765 rows\n",
            "processed 770 rows\n",
            "processed 775 rows\n",
            "processed 780 rows\n",
            "processed 785 rows\n",
            "processed 790 rows\n",
            "processed 795 rows\n",
            "processed 800 rows\n",
            "processed 805 rows\n",
            "processed 810 rows\n",
            "processed 815 rows\n",
            "processed 820 rows\n",
            "processed 825 rows\n",
            "processed 830 rows\n",
            "processed 835 rows\n",
            "processed 840 rows\n",
            "processed 845 rows\n",
            "processed 850 rows\n",
            "processed 855 rows\n",
            "processed 860 rows\n",
            "processed 865 rows\n",
            "processed 870 rows\n",
            "processed 875 rows\n",
            "processed 880 rows\n",
            "processed 885 rows\n",
            "processed 890 rows\n",
            "processed 895 rows\n",
            "processed 900 rows\n",
            "processed 905 rows\n",
            "processed 910 rows\n",
            "processed 915 rows\n",
            "processed 920 rows\n",
            "processed 925 rows\n",
            "processed 930 rows\n",
            "processed 935 rows\n",
            "processed 940 rows\n",
            "processed 945 rows\n",
            "processed 950 rows\n",
            "processed 955 rows\n",
            "processed 960 rows\n",
            "processed 965 rows\n",
            "processed 970 rows\n",
            "processed 975 rows\n",
            "processed 980 rows\n",
            "processed 985 rows\n",
            "processed 990 rows\n",
            "processed 995 rows\n",
            "processed 1000 rows\n",
            "processed 1005 rows\n",
            "processed 1010 rows\n",
            "processed 1015 rows\n",
            "processed 1020 rows\n",
            "processed 1025 rows\n",
            "processed 1030 rows\n",
            "processed 1035 rows\n",
            "processed 1040 rows\n",
            "processed 1045 rows\n",
            "processed 1050 rows\n",
            "processed 1055 rows\n"
          ]
        }
      ],
      "source": [
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# =============================================================================\n",
        "# Outputs (minimal)\n",
        "# =============================================================================\n",
        "\n",
        "class Step1FunctionalExperiment(BaseModel):\n",
        "    functional_experiment: Literal[0, 1] = Field(..., description=\"1 if a functional experiment is reported in the abstract, else 0.\")\n",
        "\n",
        "Criterion = Literal[\"PS3\", \"BS3\", \"not_clear\"]\n",
        "Strength = Literal[\"very_strong\", \"strong\", \"moderate\", \"supporting\", \"not_clear\"]\n",
        "\n",
        "class Step2ACMGPS3BS3(BaseModel):\n",
        "    criterion: Criterion = Field(..., description=\"PS3 if damaging effect; BS3 if no damaging effect; not_clear if unclear.\")\n",
        "    strength: Strength = Field(..., description=\"very_strong/strong/moderate/supporting; not_clear if cannot be determined from abstract.\")\n",
        "\n",
        "# =============================================================================\n",
        "# Prompts (separated to avoid confounding)\n",
        "# =============================================================================\n",
        "\n",
        "SYSTEM_STEP1 = \"\"\"You are a clinical variant interpretation curator.\n",
        "\n",
        "Task: Decide ONLY whether the abstract reports experimental functional evidence about the effect of one or more genetic variants (“variant/mutation/allele/mutant”) on gene product function (such as protein or RNA).\n",
        "\n",
        "Return functional_experiment=1 if the abstract includes BOTH:\n",
        "A) Variant-level subject:\n",
        "   - One or more specific variants are tested OR the abstract clearly studies “patient mutations / mutant constructs / alleles” of the gene (even if the exact variant notation is not listed in the abstract).\n",
        "AND\n",
        "B) Experimental functional readout + result:\n",
        "   - The abstract reports a measured experimental outcome for those variants (abnormal OR normal) relevant to gene/protein/RNA function or a disease-relevant functional pathway/output.\n",
        "\n",
        "Count as functional_experiment=1 if results are reported from ANY of the following experimental evidence types:\n",
        "\n",
        "1) Protein / biochemical function (in vitro or in cells):\n",
        "   - Enzymatic activity, catalytic rate, substrate turnover\n",
        "   - Binding/interaction, complex formation\n",
        "   - Protein stability/half-life, folding, degradation\n",
        "   - Localization/trafficking/secretion, channel transport, receptor signaling\n",
        "   - Post-translational modification effects when tied to function\n",
        "\n",
        "2) Cell-based functional consequences:\n",
        "   - Reporter/pathway output, downstream signaling, electrophysiology\n",
        "   - Rescue/complementation assays (WT rescues; mutant fails to rescue)\n",
        "   - Cellular phenotypes tied to mechanism (e.g., DNA repair capacity, metabolic flux, viability under specific stress) with variant-specific comparison\n",
        "\n",
        "3) RNA-level functional assays (treat as functional evidence when tied to variant effect):\n",
        "   - Splicing assays (patient RNA/cDNA, RT-PCR, minigene) showing exon skipping/intron retention/aberrant transcripts\n",
        "   - mRNA stability / nonsense-mediated decay (NMD) evidence attributable to the variant\n",
        "   - Translation efficiency / processing when experimentally measured\n",
        "(These are explicitly discussed as informative functional approaches at the mRNA level.) \n",
        "\n",
        "4) Model systems (cellular or organismal) WITH variant-level manipulation:\n",
        "   - Knock-in / engineered variant models, variant-specific phenotypes, or variant-specific functional rescue.\n",
        "\n",
        "5) Patient-derived material (allow as functional evidence when variant attribution is plausible):\n",
        "   - Functional readouts measured in patient cells/tissue (e.g., enzyme activity, pathway output, electrophysiology, splicing defects),\n",
        "     especially when the abstract indicates homozygosity or clearly links the functional result to the variant(s).\n",
        "(Note: patient-derived assays can reflect broader genetic background, but they can still constitute functional evidence in an abstract-level screen.) \n",
        "\n",
        "Important screening rule (to reduce false negatives):\n",
        "- Do NOT require the abstract to list the exact variant IDs. If it clearly reports functional testing/results for “mutations/variants” in the gene, count it.\n",
        "\n",
        "Do NOT count as functional_experiment=0 if the abstract is ONLY:\n",
        "- In silico/computational predictions with no wet-lab assay.\n",
        "- Pure genetic association, linkage, segregation, case series, phenotype description without a functional readout.\n",
        "- Gene/pathway biology studies (KO/overexpression/mechanistic work) that do NOT test patient variants / mutant constructs.\n",
        "- Omics/expression profiling alone (RNA-seq, “gene expression changes”) without linking the result to a tested variant’s effect on RNA/protein (exceptions: explicit NMD/mRNA stability or variant-driven splicing outcomes).\n",
        "\n",
        "Tie-breaker:\n",
        "- If you see any explicit wet-lab assay + a stated result about variants/mutations (even broadly described), return 1.\n",
        "\n",
        "Return only: functional_experiment (0 or 1).\n",
        "\"\"\"\n",
        "\n",
        "SYSTEM_STEP2 = \"\"\"You are a variant interpretation curator.\n",
        "\n",
        "Input: (1) a genetic variant IDs, and (2) an abstract that contains variant-level functional evidence.\n",
        "Task: For the TARGET VARIANT ONLY, assign:\n",
        "- criterion: PS3, BS3, or not_clear\n",
        "- strength: very_strong, strong, moderate, supporting, or not_clear\n",
        "Use ONLY what is explicitly stated in the abstract. Be conservative.\n",
        "\n",
        "========================\n",
        "A) Target-variant gating\n",
        "========================\n",
        "1) First, check whether the abstract explicitly refers to the TARGET VARIANT (any equivalent representation counts):\n",
        "   - protein form (e.g., p.Arg123Trp), cDNA form (e.g., c.370C>T), genomic form, rsID, or clearly stated alias.\n",
        "2) If you cannot confidently match the abstract’s variant(s) to the TARGET VARIANT, then:\n",
        "   criterion = not_clear; strength = not_clear.\n",
        "\n",
        "Do NOT “borrow” evidence from other variants in the abstract.\n",
        "\n",
        "========================================\n",
        "B) Direction (PS3 vs BS3 vs not_clear)\n",
        "========================================\n",
        "Assign direction only if the abstract clearly indicates the target variant’s functional readout relative to a NORMAL comparator/baseline.\n",
        "\n",
        "- PS3: target variant shows functionally abnormal effect relative to a normal comparator\n",
        "  (e.g., wild-type, healthy/normal control, normal baseline) AND the abnormal direction is consistent with a stated disease mechanism *or* the abstract explicitly frames the result as abnormal/defective.\n",
        "- BS3: target variant shows functionally normal/no meaningful difference relative to a normal comparator.\n",
        "- not_clear if ANY apply:\n",
        "  * comparator/baseline is unclear or missing,\n",
        "  * the target variant result is described as intermediate/partial/hypomorphic without a clear categorical threshold,\n",
        "  * mixed/conflicting outcomes across assays for the target variant without a clear rationale to privilege one,\n",
        "  * the abstract does not clearly state abnormal vs normal for the target variant.\n",
        "\n",
        "If criterion = not_clear, strength must be not_clear.\n",
        "\n",
        "========================================\n",
        "C) Strength (validation-aware; abstract-only)\n",
        "========================================\n",
        "Strength reflects the *clinical validation* of the specific assay instance as reported, not the assay class.\n",
        "\n",
        "Before assigning any non–not_clear strength, the abstract should make it reasonable to infer:\n",
        "- a clear normal comparator/control (e.g., WT/normal), AND\n",
        "- replication (technical and/or biological replicates) OR a clear statement that this assay instance is an established/validated/standardized/kit-based test with defined performance. \n",
        "\n",
        "If the abstract lacks both (i) a clear comparator/control and (ii) either replicates or an explicit “established/validated/kit” claim, set strength = not_clear.\n",
        "\n",
        "----------------------------------------\n",
        "C1) If formal calibration/statistics are reported\n",
        "----------------------------------------\n",
        "If the abstract explicitly reports rigorous statistical calibration enabling an Odds of Pathogenicity (OddsPath), likelihood ratios, or sensitivity/specificity with defined thresholds that map assay performance to evidence strength, then use these thresholds:\n",
        "\n",
        "For PS3:\n",
        "- very_strong if OddsPath > 350\n",
        "- strong       if OddsPath > 18.7\n",
        "- moderate     if OddsPath > 4.3\n",
        "- supporting   if OddsPath > 2.1\n",
        "- not_clear    if OddsPath is in the indeterminate range (0.48–2.1) or not clearly mapped\n",
        "\n",
        "For BS3 (note: no “very_strong” in this framework):\n",
        "- strong       if OddsPath < 0.053\n",
        "- moderate     if OddsPath < 0.23\n",
        "- supporting   if OddsPath < 0.48\n",
        "- not_clear    if OddsPath is in the indeterminate range (0.48–2.1) or not clearly mapped\n",
        "\n",
        "----------------------------------------\n",
        "C2) If NO formal calibration/statistics are reported\n",
        "----------------------------------------\n",
        "Then strength is based on stated validation controls:\n",
        "\n",
        "- moderate:\n",
        "  * abstract explicitly states >= 11 total validation variant controls (mix of known pathogenic and known benign)\n",
        "    used to demonstrate the assay distinguishes pathogenic vs benign variants.\n",
        "\n",
        "- supporting:\n",
        "  * abstract states controls + replicates, but has <= 10 validation variant controls, OR \n",
        "  * abstract says the assay class is broadly accepted/previously validated/kit with defined performance,\n",
        "    but this specific instance does not document its controls/replicates/validation counts. \n",
        "\n",
        "- strong / very_strong:\n",
        "  * do NOT assign without explicit formal calibration/statistical mapping as above.\n",
        "\n",
        "----------------------------------------\n",
        "C3) Multiple assays / conflicting results\n",
        "----------------------------------------\n",
        "If multiple assays are reported for the target variant:\n",
        "- If consistent (all abnormal or all normal): apply the single highest strength justified by the most validated assay instance described.\n",
        "- If conflicting:\n",
        "  * If the abstract explicitly indicates one assay is more well-validated and/or more reflective of the disease mechanism, you may use that one.\n",
        "  * Otherwise: criterion = not_clear; strength = not_clear.\n",
        "\n",
        "========================\n",
        "Output format (strict)\n",
        "========================\n",
        "Return ONLY a JSON object with exactly:\n",
        "{\"criterion\": \"...\", \"strength\": \"...\"}\n",
        "No extra keys, no explanation.\n",
        "\"\"\"\n",
        "\n",
        "USER_TEMPLATE = \"\"\"PMID: {pmid}\n",
        "\n",
        "Abstract:\n",
        "\\\"\\\"\\\"{abstract}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# OpenAI call helpers (no temperature)\n",
        "# =============================================================================\n",
        "\n",
        "class LLMCallError(Exception):\n",
        "    pass\n",
        "\n",
        "def _reasoning_kwargs(model_name: str) -> dict:\n",
        "    return {\"reasoning\": {\"effort\": \"low\"}} if model_name.startswith(\"o\") else {}\n",
        "\n",
        "@retry(\n",
        "    reraise=True,\n",
        "    stop=stop_after_attempt(4),\n",
        "    wait=wait_exponential(multiplier=1, min=1, max=20),\n",
        "    retry=retry_if_exception_type(LLMCallError),\n",
        ")\n",
        "def step1_functional_experiment(model_name: str, pmid: str, abstract: str) -> Step1FunctionalExperiment:\n",
        "    if not isinstance(abstract, str) or not abstract.strip():\n",
        "        return Step1FunctionalExperiment(functional_experiment=0)\n",
        "    try:\n",
        "        resp = client.responses.parse(\n",
        "            model=model_name,\n",
        "            input=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_STEP1},\n",
        "                {\"role\": \"user\", \"content\": USER_TEMPLATE.format(pmid=pmid, abstract=abstract)},\n",
        "            ],\n",
        "            text_format=Step1FunctionalExperiment,\n",
        "            **_reasoning_kwargs(model_name),\n",
        "        )\n",
        "        out = resp.output_parsed\n",
        "        out.functional_experiment = 1 if int(out.functional_experiment) == 1 else 0\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        raise LLMCallError(str(e)) from e\n",
        "\n",
        "@retry(\n",
        "    reraise=True,\n",
        "    stop=stop_after_attempt(4),\n",
        "    wait=wait_exponential(multiplier=1, min=1, max=20),\n",
        "    retry=retry_if_exception_type(LLMCallError),\n",
        ")\n",
        "def step2_ps3_bs3(model_name: str, pmid: str, abstract: str) -> Step2ACMGPS3BS3:\n",
        "    if not isinstance(abstract, str) or not abstract.strip():\n",
        "        return Step2ACMGPS3BS3(criterion=\"not_clear\", strength=\"not_clear\")\n",
        "    try:\n",
        "        resp = client.responses.parse(\n",
        "            model=model_name,\n",
        "            input=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_STEP2},\n",
        "                {\"role\": \"user\", \"content\": USER_TEMPLATE.format(pmid=pmid, abstract=abstract)},\n",
        "            ],\n",
        "            text_format=Step2ACMGPS3BS3,\n",
        "            **_reasoning_kwargs(model_name),\n",
        "        )\n",
        "        out = resp.output_parsed\n",
        "\n",
        "        # Guardrails: if criterion not_clear, strength should not be a concrete label\n",
        "        # (since your single-label output can't represent \"PS3 + not_clear strength\" cleanly)\n",
        "        if out.criterion == \"not_clear\":\n",
        "            out.strength = \"not_clear\"\n",
        "\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        raise LLMCallError(str(e)) from e\n",
        "\n",
        "# =============================================================================\n",
        "# Saving\n",
        "# =============================================================================\n",
        "\n",
        "def _save_df(df: pd.DataFrame, out_path: str) -> None:\n",
        "    p = out_path.lower()\n",
        "    if p.endswith(\".parquet\"):\n",
        "        df.to_parquet(out_path, index=False)\n",
        "    else:\n",
        "        df.to_csv(out_path, index=False)\n",
        "\n",
        "# =============================================================================\n",
        "# Main runner\n",
        "# =============================================================================\n",
        "\n",
        "def run_functional_evidence_labeling(\n",
        "    df: pd.DataFrame,\n",
        "    out_path: str,\n",
        "    pmid_col: str = \"pmid\",\n",
        "    abstract_col: str = \"abstract\",\n",
        "    models=(\"o4-mini\", \"gpt-4o-mini\"),\n",
        "    overwrite: bool = False,\n",
        "    save_every: int = 50,\n",
        "    sleep_s: float = 0.0,\n",
        ") -> pd.DataFrame:\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Ensure output cols exist with correct dtypes\n",
        "    for model_name in models:\n",
        "        func_col = f\"{model_name}_functional_experiment\"\n",
        "        ev_col = f\"{model_name}_evidence\"\n",
        "\n",
        "        if func_col not in df.columns:\n",
        "            df[func_col] = pd.Series([pd.NA] * len(df), dtype=\"Int64\")\n",
        "        else:\n",
        "            df[func_col] = df[func_col].astype(\"Int64\")\n",
        "\n",
        "        if ev_col not in df.columns:\n",
        "            df[ev_col] = pd.Series([pd.NA] * len(df), dtype=\"string\")\n",
        "        else:\n",
        "            df[ev_col] = df[ev_col].astype(\"string\")\n",
        "\n",
        "    processed = 0\n",
        "\n",
        "    for model_name in models:\n",
        "        func_col = f\"{model_name}_functional_experiment\"\n",
        "        ev_col = f\"{model_name}_evidence\"\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            if not overwrite and pd.notna(row.get(func_col)) and pd.notna(row.get(ev_col)):\n",
        "                continue\n",
        "\n",
        "            pmid = str(row.get(pmid_col, \"\")).strip()\n",
        "            abstract = row.get(abstract_col, \"\")\n",
        "\n",
        "            # Step 1\n",
        "            s1 = step1_functional_experiment(model_name=model_name, pmid=pmid, abstract=abstract)\n",
        "            df.at[idx, func_col] = int(s1.functional_experiment)\n",
        "\n",
        "            # Step 2 -> single evidence label\n",
        "            # if s1.functional_experiment == 0:\n",
        "            #     df.at[idx, ev_col] = \"not_applicable\"\n",
        "            # else:\n",
        "            #     s2 = step2_ps3_bs3(model_name=model_name, pmid=pmid, abstract=abstract)\n",
        "\n",
        "            #     if s2.criterion == \"not_clear\" or s2.strength == \"not_clear\":\n",
        "            #         df.at[idx, ev_col] = \"not_clear\"\n",
        "            #     else:\n",
        "            #         df.at[idx, ev_col] = f\"{s2.criterion}_{s2.strength}\"  # e.g., PS3_strong\n",
        "\n",
        "            processed += 1\n",
        "            if save_every and (processed % save_every == 0):\n",
        "                _save_df(df, out_path)\n",
        "\n",
        "            if processed % 10 == 0:\n",
        "                print(f\"processed {processed//2} rows\")\n",
        "\n",
        "            if sleep_s:\n",
        "                time.sleep(sleep_s)\n",
        "\n",
        "    _save_df(df, out_path)\n",
        "    return df\n",
        "\n",
        "\n",
        "labeled_df = run_functional_evidence_labeling(\n",
        "    all_abstracts_df,\n",
        "    out_path=\"../data/abstract_class_bench_functional_labels_v2.csv\",\n",
        "    overwrite=False,\n",
        "    save_every=50,\n",
        "    sleep_s=0.0,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "90846d50",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pmid</th>\n",
              "      <th>abstract</th>\n",
              "      <th>evidence</th>\n",
              "      <th>functional_experiment</th>\n",
              "      <th>gpt-4o-mini_functional_experiment</th>\n",
              "      <th>gpt-4o-mini_evidence</th>\n",
              "      <th>o4-mini_functional_experiment</th>\n",
              "      <th>o4-mini_evidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9634518</td>\n",
              "      <td>Phenylketonuria (PKU) and mild hyperphenylalan...</td>\n",
              "      <td>PS3_strong</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3615198</td>\n",
              "      <td>Classical Phenylketonuria (PKU) is an autosoma...</td>\n",
              "      <td>PS3_strong</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15319459</td>\n",
              "      <td>Tetrahydrobiopterin (BH4)-responsive phenylala...</td>\n",
              "      <td>PS3_strong</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24401910</td>\n",
              "      <td>Phenylalanine hydroxylase (PAH) deficiency is ...</td>\n",
              "      <td>PS3_strong</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>29706350</td>\n",
              "      <td>Phosphatase and tensin homolog (PTEN) is a tum...</td>\n",
              "      <td>BS3_supporting</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1053</th>\n",
              "      <td>35699829</td>\n",
              "      <td>Leber's hereditary optic neuropathy (LHON) is ...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>17612745</td>\n",
              "      <td>The clinical profile and prognosis of patients...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1055</th>\n",
              "      <td>15322508</td>\n",
              "      <td>There were an estimated 10 million new cases, ...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056</th>\n",
              "      <td>20228067</td>\n",
              "      <td>Mutations in the COCH (coagulation factor C ho...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1057</th>\n",
              "      <td>30214072</td>\n",
              "      <td>To investigate immune tolerance induction with...</td>\n",
              "      <td>non_PS3_BS3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1058 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          pmid                                           abstract  \\\n",
              "0      9634518  Phenylketonuria (PKU) and mild hyperphenylalan...   \n",
              "1      3615198  Classical Phenylketonuria (PKU) is an autosoma...   \n",
              "2     15319459  Tetrahydrobiopterin (BH4)-responsive phenylala...   \n",
              "3     24401910  Phenylalanine hydroxylase (PAH) deficiency is ...   \n",
              "4     29706350  Phosphatase and tensin homolog (PTEN) is a tum...   \n",
              "...        ...                                                ...   \n",
              "1053  35699829  Leber's hereditary optic neuropathy (LHON) is ...   \n",
              "1054  17612745  The clinical profile and prognosis of patients...   \n",
              "1055  15322508  There were an estimated 10 million new cases, ...   \n",
              "1056  20228067  Mutations in the COCH (coagulation factor C ho...   \n",
              "1057  30214072  To investigate immune tolerance induction with...   \n",
              "\n",
              "            evidence  functional_experiment  \\\n",
              "0         PS3_strong                      1   \n",
              "1         PS3_strong                      1   \n",
              "2         PS3_strong                      1   \n",
              "3         PS3_strong                      1   \n",
              "4     BS3_supporting                      1   \n",
              "...              ...                    ...   \n",
              "1053     non_PS3_BS3                      0   \n",
              "1054     non_PS3_BS3                      0   \n",
              "1055     non_PS3_BS3                      0   \n",
              "1056     non_PS3_BS3                      0   \n",
              "1057     non_PS3_BS3                      0   \n",
              "\n",
              "      gpt-4o-mini_functional_experiment  gpt-4o-mini_evidence  \\\n",
              "0                                     0                   NaN   \n",
              "1                                     1                   NaN   \n",
              "2                                     1                   NaN   \n",
              "3                                     0                   NaN   \n",
              "4                                     1                   NaN   \n",
              "...                                 ...                   ...   \n",
              "1053                                  1                   NaN   \n",
              "1054                                  1                   NaN   \n",
              "1055                                  0                   NaN   \n",
              "1056                                  1                   NaN   \n",
              "1057                                  0                   NaN   \n",
              "\n",
              "      o4-mini_functional_experiment  o4-mini_evidence  \n",
              "0                                 0               NaN  \n",
              "1                                 1               NaN  \n",
              "2                                 1               NaN  \n",
              "3                                 0               NaN  \n",
              "4                                 1               NaN  \n",
              "...                             ...               ...  \n",
              "1053                              1               NaN  \n",
              "1054                              0               NaN  \n",
              "1055                              0               NaN  \n",
              "1056                              1               NaN  \n",
              "1057                              0               NaN  \n",
              "\n",
              "[1058 rows x 8 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labeled_df = pd.read_csv(\"../data/abstract_class_bench_functional_labels.csv\")\n",
        "labeled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "49104a65",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CLASSIFICATION METRICS: Functional Experiment Prediction\n",
            "================================================================================\n",
            "\n",
            "True Label: functional_experiment (binary: 0 or 1)\n",
            "Total samples: 1058\n",
            "  Class 0: 529\n",
            "  Class 1: 529\n",
            "\n",
            "================================================================================\n",
            "\n",
            "GPT-4O-MINI\n",
            "--------------------------------------------------------------------------------\n",
            "  Accuracy:           0.7429\n",
            "  Precision (PPV):    0.6854\n",
            "  Recall (Sensitivity): 0.8979\n",
            "  F1 Score:          0.7774\n",
            "  Specificity (TNR): 0.5879\n",
            "  NPV:               0.8521\n",
            "  ROC-AUC:           0.7429\n",
            "  Average Precision: 0.6665\n",
            "\n",
            "  Confusion Matrix:\n",
            "                        Predicted 0     Predicted 1\n",
            "           Actual 0             311             218\n",
            "           Actual 1              54             475\n",
            "\n",
            "  Detailed Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "No Functional Exp     0.8521    0.5879    0.6957       529\n",
            "   Functional Exp     0.6854    0.8979    0.7774       529\n",
            "\n",
            "         accuracy                         0.7429      1058\n",
            "        macro avg     0.7687    0.7429    0.7366      1058\n",
            "     weighted avg     0.7687    0.7429    0.7366      1058\n",
            "\n",
            "\n",
            "O4-MINI\n",
            "--------------------------------------------------------------------------------\n",
            "  Accuracy:           0.7637\n",
            "  Precision (PPV):    0.7123\n",
            "  Recall (Sensitivity): 0.8847\n",
            "  F1 Score:          0.7892\n",
            "  Specificity (TNR): 0.6427\n",
            "  NPV:               0.8479\n",
            "  ROC-AUC:           0.7637\n",
            "  Average Precision: 0.6878\n",
            "\n",
            "  Confusion Matrix:\n",
            "                        Predicted 0     Predicted 1\n",
            "           Actual 0             340             189\n",
            "           Actual 1              61             468\n",
            "\n",
            "  Detailed Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "No Functional Exp     0.8479    0.6427    0.7312       529\n",
            "   Functional Exp     0.7123    0.8847    0.7892       529\n",
            "\n",
            "         accuracy                         0.7637      1058\n",
            "        macro avg     0.7801    0.7637    0.7602      1058\n",
            "     weighted avg     0.7801    0.7637    0.7602      1058\n",
            "\n",
            "\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'gpt-4o-mini': {'Accuracy': 0.7429111531190926,\n",
              "  'Precision (PPV)': 0.6854256854256854,\n",
              "  'Recall (Sensitivity)': 0.8979206049149339,\n",
              "  'F1 Score': 0.7774140752864157,\n",
              "  'Specificity (TNR)': 0.5879017013232514,\n",
              "  'NPV': 0.852054794520548,\n",
              "  'ROC-AUC': 0.7429111531190926,\n",
              "  'Average Precision': 0.6664975436241976,\n",
              "  'True Positives (TP)': 475,\n",
              "  'True Negatives (TN)': 311,\n",
              "  'False Positives (FP)': 218,\n",
              "  'False Negatives (FN)': 54,\n",
              "  'Confusion Matrix': array([[311, 218],\n",
              "         [ 54, 475]])},\n",
              " 'o4-mini': {'Accuracy': 0.7637051039697542,\n",
              "  'Precision (PPV)': 0.7123287671232876,\n",
              "  'Recall (Sensitivity)': 0.8846880907372401,\n",
              "  'F1 Score': 0.7892074198988196,\n",
              "  'Specificity (TNR)': 0.6427221172022685,\n",
              "  'NPV': 0.8478802992518704,\n",
              "  'ROC-AUC': 0.7637051039697542,\n",
              "  'Average Precision': 0.6878447315948935,\n",
              "  'True Positives (TP)': 468,\n",
              "  'True Negatives (TN)': 340,\n",
              "  'False Positives (FP)': 189,\n",
              "  'False Negatives (FN)': 61,\n",
              "  'Confusion Matrix': array([[340, 189],\n",
              "         [ 61, 468]])}}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, \n",
        "    roc_auc_score, average_precision_score\n",
        ")\n",
        "\n",
        "def calculate_classification_metrics(\n",
        "    df: pd.DataFrame,\n",
        "    true_label_col: str,\n",
        "    model_predictions: dict,\n",
        "    task_name: str = \"Classification Task\",\n",
        "    class_names: tuple = None,\n",
        "    print_results: bool = True\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Calculate classification metrics for multiple models.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame containing true labels and predictions\n",
        "    true_label_col : str\n",
        "        Column name for true labels\n",
        "    model_predictions : dict\n",
        "        Dictionary mapping model names to prediction column names\n",
        "        e.g., {'model1': 'model1_pred_col', 'model2': 'model2_pred_col'}\n",
        "    task_name : str\n",
        "        Name of the classification task (for display purposes)\n",
        "    class_names : tuple, optional\n",
        "        Tuple of class names for display (e.g., ('Class 0', 'Class 1'))\n",
        "        If None, will use generic names\n",
        "    print_results : bool\n",
        "        Whether to print formatted results\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary mapping model names to their metrics dictionaries\n",
        "    \"\"\"\n",
        "    # Remove rows with missing true labels or predictions\n",
        "    required_cols = [true_label_col] + list(model_predictions.values())\n",
        "    df_clean = df.dropna(subset=required_cols).copy()\n",
        "    \n",
        "    if len(df_clean) == 0:\n",
        "        raise ValueError(\"No valid rows after removing missing values\")\n",
        "    \n",
        "    # True labels\n",
        "    y_true = df_clean[true_label_col].values\n",
        "    \n",
        "    # Get predictions for each model\n",
        "    model_preds = {}\n",
        "    for model_name, pred_col in model_predictions.items():\n",
        "        model_preds[model_name] = df_clean[pred_col].values\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for model_name, y_pred in model_preds.items():\n",
        "        # Basic metrics\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "        \n",
        "        # Additional metrics\n",
        "        try:\n",
        "            roc_auc = roc_auc_score(y_true, y_pred)\n",
        "        except ValueError:\n",
        "            roc_auc = None\n",
        "        \n",
        "        try:\n",
        "            avg_precision = average_precision_score(y_true, y_pred)\n",
        "        except ValueError:\n",
        "            avg_precision = None\n",
        "        \n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        \n",
        "        # Additional derived metrics\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = recall  # Same as recall\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative Predictive Value\n",
        "        ppv = precision  # Positive Predictive Value (same as precision)\n",
        "        \n",
        "        results[model_name] = {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (PPV)': precision,\n",
        "            'Recall (Sensitivity)': recall,\n",
        "            'F1 Score': f1,\n",
        "            'Specificity (TNR)': specificity,\n",
        "            'NPV': npv,\n",
        "            'ROC-AUC': roc_auc,\n",
        "            'Average Precision': avg_precision,\n",
        "            'True Positives (TP)': tp,\n",
        "            'True Negatives (TN)': tn,\n",
        "            'False Positives (FP)': fp,\n",
        "            'False Negatives (FN)': fn,\n",
        "            'Confusion Matrix': cm\n",
        "        }\n",
        "    \n",
        "    if print_results:\n",
        "        # Display results in a nice format\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"CLASSIFICATION METRICS: {task_name}\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\nTrue Label: {true_label_col} (binary: 0 or 1)\")\n",
        "        print(f\"Total samples: {len(df_clean)}\")\n",
        "        print(f\"  Class 0: {(y_true == 0).sum()}\")\n",
        "        print(f\"  Class 1: {(y_true == 1).sum()}\")\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        \n",
        "        for model_name, metrics in results.items():\n",
        "            print(f\"\\n{model_name.upper()}\")\n",
        "            print(\"-\" * 80)\n",
        "            \n",
        "            # Main metrics\n",
        "            print(f\"  Accuracy:           {metrics['Accuracy']:.4f}\")\n",
        "            print(f\"  Precision (PPV):    {metrics['Precision (PPV)']:.4f}\")\n",
        "            print(f\"  Recall (Sensitivity): {metrics['Recall (Sensitivity)']:.4f}\")\n",
        "            print(f\"  F1 Score:          {metrics['F1 Score']:.4f}\")\n",
        "            print(f\"  Specificity (TNR): {metrics['Specificity (TNR)']:.4f}\")\n",
        "            print(f\"  NPV:               {metrics['NPV']:.4f}\")\n",
        "            \n",
        "            if metrics['ROC-AUC'] is not None:\n",
        "                print(f\"  ROC-AUC:           {metrics['ROC-AUC']:.4f}\")\n",
        "            if metrics['Average Precision'] is not None:\n",
        "                print(f\"  Average Precision: {metrics['Average Precision']:.4f}\")\n",
        "            \n",
        "            # Confusion matrix\n",
        "            print(f\"\\n  Confusion Matrix:\")\n",
        "            print(f\"    {'':>15} {'Predicted 0':>15} {'Predicted 1':>15}\")\n",
        "            print(f\"    {'Actual 0':>15} {metrics['True Negatives (TN)']:>15} {metrics['False Positives (FP)']:>15}\")\n",
        "            print(f\"    {'Actual 1':>15} {metrics['False Negatives (FN)']:>15} {metrics['True Positives (TP)']:>15}\")\n",
        "            \n",
        "            # Classification report\n",
        "            target_names = class_names if class_names else ['Class 0', 'Class 1']\n",
        "            print(f\"\\n  Detailed Classification Report:\")\n",
        "            print(classification_report(y_true, model_preds[model_name], target_names=target_names, digits=4))\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Use the function\n",
        "calculate_classification_metrics(\n",
        "    df=labeled_df,\n",
        "    true_label_col='functional_experiment',\n",
        "    model_predictions={\n",
        "        'gpt-4o-mini': 'gpt-4o-mini_functional_experiment',\n",
        "        'o4-mini': 'o4-mini_functional_experiment'\n",
        "    },\n",
        "    task_name='Functional Experiment Prediction',\n",
        "    class_names=('No Functional Exp', 'Functional Exp')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144b061d",
      "metadata": {},
      "source": [
        "### Increase sensitivity (recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "00f73913",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed 5 rows\n",
            "processed 10 rows\n",
            "processed 15 rows\n",
            "processed 20 rows\n",
            "processed 25 rows\n",
            "processed 30 rows\n",
            "processed 35 rows\n",
            "processed 40 rows\n",
            "processed 45 rows\n",
            "processed 50 rows\n",
            "processed 55 rows\n",
            "processed 60 rows\n",
            "processed 65 rows\n",
            "processed 70 rows\n",
            "processed 75 rows\n",
            "processed 80 rows\n",
            "processed 85 rows\n",
            "processed 90 rows\n",
            "processed 95 rows\n",
            "processed 100 rows\n",
            "processed 105 rows\n",
            "processed 110 rows\n",
            "processed 115 rows\n",
            "processed 120 rows\n",
            "processed 125 rows\n",
            "processed 130 rows\n",
            "processed 135 rows\n",
            "processed 140 rows\n",
            "processed 145 rows\n",
            "processed 150 rows\n",
            "processed 155 rows\n",
            "processed 160 rows\n",
            "processed 165 rows\n",
            "processed 170 rows\n",
            "processed 175 rows\n",
            "processed 180 rows\n",
            "processed 185 rows\n",
            "processed 190 rows\n",
            "processed 195 rows\n",
            "processed 200 rows\n",
            "processed 205 rows\n",
            "processed 210 rows\n",
            "processed 215 rows\n",
            "processed 220 rows\n",
            "processed 225 rows\n",
            "processed 230 rows\n",
            "processed 235 rows\n",
            "processed 240 rows\n",
            "processed 245 rows\n",
            "processed 250 rows\n",
            "processed 255 rows\n",
            "processed 260 rows\n",
            "processed 265 rows\n",
            "processed 270 rows\n",
            "processed 275 rows\n",
            "processed 280 rows\n",
            "processed 285 rows\n",
            "processed 290 rows\n",
            "processed 295 rows\n",
            "processed 300 rows\n",
            "processed 305 rows\n",
            "processed 310 rows\n",
            "processed 315 rows\n",
            "processed 320 rows\n",
            "processed 325 rows\n",
            "processed 330 rows\n",
            "processed 335 rows\n",
            "processed 340 rows\n",
            "processed 345 rows\n",
            "processed 350 rows\n",
            "processed 355 rows\n",
            "processed 360 rows\n",
            "processed 365 rows\n",
            "processed 370 rows\n",
            "processed 375 rows\n",
            "processed 380 rows\n",
            "processed 385 rows\n",
            "processed 390 rows\n",
            "processed 395 rows\n",
            "processed 400 rows\n",
            "processed 405 rows\n",
            "processed 410 rows\n",
            "processed 415 rows\n",
            "processed 420 rows\n",
            "processed 425 rows\n",
            "processed 430 rows\n",
            "processed 435 rows\n",
            "processed 440 rows\n",
            "processed 445 rows\n",
            "processed 450 rows\n",
            "processed 455 rows\n",
            "processed 460 rows\n",
            "processed 465 rows\n",
            "processed 470 rows\n",
            "processed 475 rows\n",
            "processed 480 rows\n",
            "processed 485 rows\n",
            "processed 490 rows\n",
            "processed 495 rows\n",
            "processed 500 rows\n",
            "processed 505 rows\n",
            "processed 510 rows\n",
            "processed 515 rows\n",
            "processed 520 rows\n",
            "processed 525 rows\n",
            "processed 530 rows\n",
            "processed 535 rows\n",
            "processed 540 rows\n",
            "processed 545 rows\n",
            "processed 550 rows\n",
            "processed 555 rows\n",
            "processed 560 rows\n",
            "processed 565 rows\n",
            "processed 570 rows\n",
            "processed 575 rows\n",
            "processed 580 rows\n",
            "processed 585 rows\n",
            "processed 590 rows\n",
            "processed 595 rows\n",
            "processed 600 rows\n",
            "processed 605 rows\n",
            "processed 610 rows\n",
            "processed 615 rows\n",
            "processed 620 rows\n",
            "processed 625 rows\n",
            "processed 630 rows\n",
            "processed 635 rows\n",
            "processed 640 rows\n",
            "processed 645 rows\n",
            "processed 650 rows\n",
            "processed 655 rows\n",
            "processed 660 rows\n",
            "processed 665 rows\n",
            "processed 670 rows\n",
            "processed 675 rows\n",
            "processed 680 rows\n",
            "processed 685 rows\n",
            "processed 690 rows\n",
            "processed 695 rows\n",
            "processed 700 rows\n",
            "processed 705 rows\n",
            "processed 710 rows\n",
            "processed 715 rows\n",
            "processed 720 rows\n",
            "processed 725 rows\n",
            "processed 730 rows\n",
            "processed 735 rows\n",
            "processed 740 rows\n",
            "processed 745 rows\n",
            "processed 750 rows\n",
            "processed 755 rows\n",
            "processed 760 rows\n",
            "processed 765 rows\n",
            "processed 770 rows\n",
            "processed 775 rows\n",
            "processed 780 rows\n",
            "processed 785 rows\n",
            "processed 790 rows\n",
            "processed 795 rows\n",
            "processed 800 rows\n",
            "processed 805 rows\n",
            "processed 810 rows\n",
            "processed 815 rows\n",
            "processed 820 rows\n",
            "processed 825 rows\n",
            "processed 830 rows\n",
            "processed 835 rows\n",
            "processed 840 rows\n",
            "processed 845 rows\n",
            "processed 850 rows\n",
            "processed 855 rows\n",
            "processed 860 rows\n",
            "processed 865 rows\n",
            "processed 870 rows\n",
            "processed 875 rows\n",
            "processed 880 rows\n",
            "processed 885 rows\n",
            "processed 890 rows\n",
            "processed 895 rows\n",
            "processed 900 rows\n",
            "processed 905 rows\n",
            "processed 910 rows\n",
            "processed 915 rows\n",
            "processed 920 rows\n",
            "processed 925 rows\n",
            "processed 930 rows\n",
            "processed 935 rows\n",
            "processed 940 rows\n",
            "processed 945 rows\n",
            "processed 950 rows\n",
            "processed 955 rows\n",
            "processed 960 rows\n",
            "processed 965 rows\n",
            "processed 970 rows\n",
            "processed 975 rows\n",
            "processed 980 rows\n",
            "processed 985 rows\n",
            "processed 990 rows\n",
            "processed 995 rows\n",
            "processed 1000 rows\n",
            "processed 1005 rows\n",
            "processed 1010 rows\n",
            "processed 1015 rows\n",
            "processed 1020 rows\n",
            "processed 1025 rows\n",
            "processed 1030 rows\n",
            "processed 1035 rows\n",
            "processed 1040 rows\n",
            "processed 1045 rows\n",
            "processed 1050 rows\n",
            "processed 1055 rows\n"
          ]
        }
      ],
      "source": [
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# =============================================================================\n",
        "# Outputs (minimal)\n",
        "# =============================================================================\n",
        "\n",
        "class Step1FunctionalExperiment(BaseModel):\n",
        "    functional_experiment: Literal[0, 1] = Field(..., description=\"1 if a functional experiment is reported in the abstract, else 0.\")\n",
        "\n",
        "Criterion = Literal[\"PS3\", \"BS3\", \"not_clear\"]\n",
        "Strength = Literal[\"very_strong\", \"strong\", \"moderate\", \"supporting\", \"not_clear\"]\n",
        "\n",
        "class Step2ACMGPS3BS3(BaseModel):\n",
        "    criterion: Criterion = Field(..., description=\"PS3 if damaging effect; BS3 if no damaging effect; not_clear if unclear.\")\n",
        "    strength: Strength = Field(..., description=\"very_strong/strong/moderate/supporting; not_clear if cannot be determined from abstract.\")\n",
        "\n",
        "# =============================================================================\n",
        "# Prompts (separated to avoid confounding)\n",
        "# =============================================================================\n",
        "\n",
        "SYSTEM_STEP1 = \"\"\"\n",
        "You are a clinical variant interpretation curator performing an abstract-level screen for ACMG/AMP PS3/BS3 relevance.\n",
        "\n",
        "Goal\n",
        "Decide ONLY whether the abstract contains ANY experimental (wet-lab) functional evidence about the effect of one or more genetic variants/mutations/alleles/mutants on gene product function (protein or RNA) or a disease-relevant functional pathway/output.\n",
        "\n",
        "Output\n",
        "Return ONLY: functional_experiment = 1 or 0\n",
        "\n",
        "Bias / sensitivity requirement (important)\n",
        "This screen is intentionally high-sensitivity. If there is reasonable doubt, classify as 1 so the paper can be reviewed downstream.\n",
        "Default to 1 whenever BOTH (i) variant/mutant language and (ii) any wet-lab functional assay signal are present, even if details are sparse.\n",
        "\n",
        "Classify functional_experiment = 1 if the abstract shows BOTH:\n",
        "\n",
        "A) Variant-or-mutant subject (broad; exact IDs NOT required)\n",
        "Any of the following counts:\n",
        "- Specific variant(s) listed (HGVS, rsID, amino-acid change, “c.”/“p.”, etc.)\n",
        "- “patient mutations/variants”, “disease-causing mutations”, “mutant alleles”, “allelic series”\n",
        "- “mutant constructs”, “site-directed mutants”, “missense mutants”, “variant panel”, “mutagenesis”\n",
        "- Engineered or edited variant models (knock-in, CRISPR-introduced variant, engineered mutant protein)\n",
        "- Patient-derived samples where the abstract links results to the mutation(s) (even broadly)\n",
        "\n",
        "AND\n",
        "\n",
        "B) Wet-lab functional assay + outcome statement\n",
        "There is an experimental functional readout and the abstract states an outcome for the variant(s), including qualitative direction.\n",
        "Examples of outcome language: reduced/abolished/impaired, increased/gain, altered, disrupted, restored/rescued, mislocalized, unstable, no difference/normal, defective splicing, NMD, truncated protein with loss of activity, etc.\n",
        "\n",
        "Count as functional evidence (any wet-lab) if the abstract includes one or more of:\n",
        "\n",
        "1) Protein/biochemical function (in vitro or cellular)\n",
        "- Enzymatic activity/kinetics, catalytic function, substrate turnover\n",
        "- Binding/interaction/complex formation\n",
        "- Protein stability/folding/degradation/half-life\n",
        "- Localization/trafficking/secretion\n",
        "- Channel transport, receptor/signaling output, post-translational effects tied to function\n",
        "\n",
        "2) Cell-based functional consequences\n",
        "- Reporter assays, pathway activity, electrophysiology, transport flux\n",
        "- Rescue/complementation (WT vs mutant; mutant fails to rescue or rescue restores)\n",
        "- Mechanistic cellular phenotypes tied to function (e.g., DNA repair capacity, metabolic function, stress sensitivity) with mutant-vs-WT comparison\n",
        "\n",
        "3) RNA-level functional assays attributable to a variant\n",
        "- Splicing assays (patient RNA/cDNA, RT-PCR, minigene) showing aberrant splicing\n",
        "- mRNA stability / nonsense-mediated decay (NMD) experimentally shown\n",
        "- Translation/processing efficiency when experimentally measured\n",
        "\n",
        "4) Model systems with variant-level manipulation\n",
        "- Knock-in/engineered variant models with functional or disease-relevant phenotypes and a variant-linked readout\n",
        "\n",
        "5) Patient-derived functional assays (allow, even if confounded)\n",
        "- Enzyme activity, electrophysiology, pathway output, splicing defects measured in patient cells/tissue, when the abstract links findings to the mutation(s)\n",
        "\n",
        "Strong “bias-to-1” tie-breakers\n",
        "Return 1 if ANY of the following patterns appear:\n",
        "- (“mutation/variant/mutant/allele”) + a wet-lab assay keyword (activity, assay, measured, functional, reporter, localization, stability, splicing, RT-PCR, minigene, NMD, electrophysiology, rescue)\n",
        "- The abstract claims functional impact for mutations (“mutations impair function”, “variants reduce activity”, “mutants show defective splicing”), even without numbers.\n",
        "\n",
        "Return functional_experiment = 0 ONLY when it is clearly NOT functional variant testing:\n",
        "- Purely in silico/computational prediction with no wet-lab experiment\n",
        "- Pure genetic association/segregation/case reports/phenotype-only with no functional readout\n",
        "- Gene/pathway biology experiments (KO/overexpression/mechanism) that do NOT test variants/mutant constructs\n",
        "- Expression/omics profiling alone (RNA-seq, differential expression) without variant-linked functional RNA/protein consequences\n",
        "  (Exception: explicit variant-driven splicing or experimentally shown NMD/mRNA instability)\n",
        "\n",
        "Final rule\n",
        "If you can point to (A) any variant/mutant subject AND (B) any wet-lab functional readout with an outcome claim, output 1. Otherwise output 0.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "SYSTEM_STEP2 = \"\"\"You are a variant interpretation curator.\n",
        "\n",
        "Input: (1) a genetic variant IDs, and (2) an abstract that contains variant-level functional evidence.\n",
        "Task: For the TARGET VARIANT ONLY, assign:\n",
        "- criterion: PS3, BS3, or not_clear\n",
        "- strength: very_strong, strong, moderate, supporting, or not_clear\n",
        "Use ONLY what is explicitly stated in the abstract. Be conservative.\n",
        "\n",
        "========================\n",
        "A) Target-variant gating\n",
        "========================\n",
        "1) First, check whether the abstract explicitly refers to the TARGET VARIANT (any equivalent representation counts):\n",
        "   - protein form (e.g., p.Arg123Trp), cDNA form (e.g., c.370C>T), genomic form, rsID, or clearly stated alias.\n",
        "2) If you cannot confidently match the abstract’s variant(s) to the TARGET VARIANT, then:\n",
        "   criterion = not_clear; strength = not_clear.\n",
        "\n",
        "Do NOT “borrow” evidence from other variants in the abstract.\n",
        "\n",
        "========================================\n",
        "B) Direction (PS3 vs BS3 vs not_clear)\n",
        "========================================\n",
        "Assign direction only if the abstract clearly indicates the target variant’s functional readout relative to a NORMAL comparator/baseline.\n",
        "\n",
        "- PS3: target variant shows functionally abnormal effect relative to a normal comparator\n",
        "  (e.g., wild-type, healthy/normal control, normal baseline) AND the abnormal direction is consistent with a stated disease mechanism *or* the abstract explicitly frames the result as abnormal/defective.\n",
        "- BS3: target variant shows functionally normal/no meaningful difference relative to a normal comparator.\n",
        "- not_clear if ANY apply:\n",
        "  * comparator/baseline is unclear or missing,\n",
        "  * the target variant result is described as intermediate/partial/hypomorphic without a clear categorical threshold,\n",
        "  * mixed/conflicting outcomes across assays for the target variant without a clear rationale to privilege one,\n",
        "  * the abstract does not clearly state abnormal vs normal for the target variant.\n",
        "\n",
        "If criterion = not_clear, strength must be not_clear.\n",
        "\n",
        "========================================\n",
        "C) Strength (validation-aware; abstract-only)\n",
        "========================================\n",
        "Strength reflects the *clinical validation* of the specific assay instance as reported, not the assay class.\n",
        "\n",
        "Before assigning any non–not_clear strength, the abstract should make it reasonable to infer:\n",
        "- a clear normal comparator/control (e.g., WT/normal), AND\n",
        "- replication (technical and/or biological replicates) OR a clear statement that this assay instance is an established/validated/standardized/kit-based test with defined performance. \n",
        "\n",
        "If the abstract lacks both (i) a clear comparator/control and (ii) either replicates or an explicit “established/validated/kit” claim, set strength = not_clear.\n",
        "\n",
        "----------------------------------------\n",
        "C1) If formal calibration/statistics are reported\n",
        "----------------------------------------\n",
        "If the abstract explicitly reports rigorous statistical calibration enabling an Odds of Pathogenicity (OddsPath), likelihood ratios, or sensitivity/specificity with defined thresholds that map assay performance to evidence strength, then use these thresholds:\n",
        "\n",
        "For PS3:\n",
        "- very_strong if OddsPath > 350\n",
        "- strong       if OddsPath > 18.7\n",
        "- moderate     if OddsPath > 4.3\n",
        "- supporting   if OddsPath > 2.1\n",
        "- not_clear    if OddsPath is in the indeterminate range (0.48–2.1) or not clearly mapped\n",
        "\n",
        "For BS3 (note: no “very_strong” in this framework):\n",
        "- strong       if OddsPath < 0.053\n",
        "- moderate     if OddsPath < 0.23\n",
        "- supporting   if OddsPath < 0.48\n",
        "- not_clear    if OddsPath is in the indeterminate range (0.48–2.1) or not clearly mapped\n",
        "\n",
        "----------------------------------------\n",
        "C2) If NO formal calibration/statistics are reported\n",
        "----------------------------------------\n",
        "Then strength is based on stated validation controls:\n",
        "\n",
        "- moderate:\n",
        "  * abstract explicitly states >= 11 total validation variant controls (mix of known pathogenic and known benign)\n",
        "    used to demonstrate the assay distinguishes pathogenic vs benign variants.\n",
        "\n",
        "- supporting:\n",
        "  * abstract states controls + replicates, but has <= 10 validation variant controls, OR \n",
        "  * abstract says the assay class is broadly accepted/previously validated/kit with defined performance,\n",
        "    but this specific instance does not document its controls/replicates/validation counts. \n",
        "\n",
        "- strong / very_strong:\n",
        "  * do NOT assign without explicit formal calibration/statistical mapping as above.\n",
        "\n",
        "----------------------------------------\n",
        "C3) Multiple assays / conflicting results\n",
        "----------------------------------------\n",
        "If multiple assays are reported for the target variant:\n",
        "- If consistent (all abnormal or all normal): apply the single highest strength justified by the most validated assay instance described.\n",
        "- If conflicting:\n",
        "  * If the abstract explicitly indicates one assay is more well-validated and/or more reflective of the disease mechanism, you may use that one.\n",
        "  * Otherwise: criterion = not_clear; strength = not_clear.\n",
        "\n",
        "========================\n",
        "Output format (strict)\n",
        "========================\n",
        "Return ONLY a JSON object with exactly:\n",
        "{\"criterion\": \"...\", \"strength\": \"...\"}\n",
        "No extra keys, no explanation.\n",
        "\"\"\"\n",
        "\n",
        "USER_TEMPLATE = \"\"\"PMID: {pmid}\n",
        "\n",
        "Abstract:\n",
        "\\\"\\\"\\\"{abstract}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# OpenAI call helpers (no temperature)\n",
        "# =============================================================================\n",
        "\n",
        "class LLMCallError(Exception):\n",
        "    pass\n",
        "\n",
        "def _reasoning_kwargs(model_name: str) -> dict:\n",
        "    return {\"reasoning\": {\"effort\": \"low\"}} if model_name.startswith(\"o\") else {}\n",
        "\n",
        "@retry(\n",
        "    reraise=True,\n",
        "    stop=stop_after_attempt(4),\n",
        "    wait=wait_exponential(multiplier=1, min=1, max=20),\n",
        "    retry=retry_if_exception_type(LLMCallError),\n",
        ")\n",
        "def step1_functional_experiment(model_name: str, pmid: str, abstract: str) -> Step1FunctionalExperiment:\n",
        "    if not isinstance(abstract, str) or not abstract.strip():\n",
        "        return Step1FunctionalExperiment(functional_experiment=0)\n",
        "    try:\n",
        "        resp = client.responses.parse(\n",
        "            model=model_name,\n",
        "            input=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_STEP1},\n",
        "                {\"role\": \"user\", \"content\": USER_TEMPLATE.format(pmid=pmid, abstract=abstract)},\n",
        "            ],\n",
        "            text_format=Step1FunctionalExperiment,\n",
        "            **_reasoning_kwargs(model_name),\n",
        "        )\n",
        "        out = resp.output_parsed\n",
        "        out.functional_experiment = 1 if int(out.functional_experiment) == 1 else 0\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        raise LLMCallError(str(e)) from e\n",
        "\n",
        "@retry(\n",
        "    reraise=True,\n",
        "    stop=stop_after_attempt(4),\n",
        "    wait=wait_exponential(multiplier=1, min=1, max=20),\n",
        "    retry=retry_if_exception_type(LLMCallError),\n",
        ")\n",
        "def step2_ps3_bs3(model_name: str, pmid: str, abstract: str) -> Step2ACMGPS3BS3:\n",
        "    if not isinstance(abstract, str) or not abstract.strip():\n",
        "        return Step2ACMGPS3BS3(criterion=\"not_clear\", strength=\"not_clear\")\n",
        "    try:\n",
        "        resp = client.responses.parse(\n",
        "            model=model_name,\n",
        "            input=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_STEP2},\n",
        "                {\"role\": \"user\", \"content\": USER_TEMPLATE.format(pmid=pmid, abstract=abstract)},\n",
        "            ],\n",
        "            text_format=Step2ACMGPS3BS3,\n",
        "            **_reasoning_kwargs(model_name),\n",
        "        )\n",
        "        out = resp.output_parsed\n",
        "\n",
        "        # Guardrails: if criterion not_clear, strength should not be a concrete label\n",
        "        # (since your single-label output can't represent \"PS3 + not_clear strength\" cleanly)\n",
        "        if out.criterion == \"not_clear\":\n",
        "            out.strength = \"not_clear\"\n",
        "\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        raise LLMCallError(str(e)) from e\n",
        "\n",
        "# =============================================================================\n",
        "# Saving\n",
        "# =============================================================================\n",
        "\n",
        "def _save_df(df: pd.DataFrame, out_path: str) -> None:\n",
        "    p = out_path.lower()\n",
        "    if p.endswith(\".parquet\"):\n",
        "        df.to_parquet(out_path, index=False)\n",
        "    else:\n",
        "        df.to_csv(out_path, index=False)\n",
        "\n",
        "# =============================================================================\n",
        "# Main runner\n",
        "# =============================================================================\n",
        "\n",
        "def run_functional_evidence_labeling(\n",
        "    df: pd.DataFrame,\n",
        "    out_path: str,\n",
        "    pmid_col: str = \"pmid\",\n",
        "    abstract_col: str = \"abstract\",\n",
        "    models=(\"o4-mini\", \"gpt-4o-mini\"),\n",
        "    overwrite: bool = False,\n",
        "    save_every: int = 50,\n",
        "    sleep_s: float = 0.0,\n",
        ") -> pd.DataFrame:\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Ensure output cols exist with correct dtypes\n",
        "    for model_name in models:\n",
        "        func_col = f\"{model_name}_functional_experiment\"\n",
        "        ev_col = f\"{model_name}_evidence\"\n",
        "\n",
        "        if func_col not in df.columns:\n",
        "            df[func_col] = pd.Series([pd.NA] * len(df), dtype=\"Int64\")\n",
        "        else:\n",
        "            df[func_col] = df[func_col].astype(\"Int64\")\n",
        "\n",
        "        if ev_col not in df.columns:\n",
        "            df[ev_col] = pd.Series([pd.NA] * len(df), dtype=\"string\")\n",
        "        else:\n",
        "            df[ev_col] = df[ev_col].astype(\"string\")\n",
        "\n",
        "    processed = 0\n",
        "\n",
        "    for model_name in models:\n",
        "        func_col = f\"{model_name}_functional_experiment\"\n",
        "        ev_col = f\"{model_name}_evidence\"\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            if not overwrite and pd.notna(row.get(func_col)) and pd.notna(row.get(ev_col)):\n",
        "                continue\n",
        "\n",
        "            pmid = str(row.get(pmid_col, \"\")).strip()\n",
        "            abstract = row.get(abstract_col, \"\")\n",
        "\n",
        "            # Step 1\n",
        "            s1 = step1_functional_experiment(model_name=model_name, pmid=pmid, abstract=abstract)\n",
        "            df.at[idx, func_col] = int(s1.functional_experiment)\n",
        "\n",
        "            # Step 2 -> single evidence label\n",
        "            # if s1.functional_experiment == 0:\n",
        "            #     df.at[idx, ev_col] = \"not_applicable\"\n",
        "            # else:\n",
        "            #     s2 = step2_ps3_bs3(model_name=model_name, pmid=pmid, abstract=abstract)\n",
        "\n",
        "            #     if s2.criterion == \"not_clear\" or s2.strength == \"not_clear\":\n",
        "            #         df.at[idx, ev_col] = \"not_clear\"\n",
        "            #     else:\n",
        "            #         df.at[idx, ev_col] = f\"{s2.criterion}_{s2.strength}\"  # e.g., PS3_strong\n",
        "\n",
        "            processed += 1\n",
        "            if save_every and (processed % save_every == 0):\n",
        "                _save_df(df, out_path)\n",
        "\n",
        "            if processed % 10 == 0:\n",
        "                print(f\"processed {processed//2} rows\")\n",
        "\n",
        "            if sleep_s:\n",
        "                time.sleep(sleep_s)\n",
        "\n",
        "    _save_df(df, out_path)\n",
        "    return df\n",
        "\n",
        "\n",
        "labeled_df_highrecall = run_functional_evidence_labeling(\n",
        "    all_abstracts_df,\n",
        "    out_path=\"../data/abstract_class_bench_functional_labels_highrecall.csv\",\n",
        "    overwrite=False,\n",
        "    save_every=50,\n",
        "    sleep_s=0.0,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9bbb121",
      "metadata": {},
      "outputs": [],
      "source": [
        "labeled_df_highrecall = pd.read_csv(\"../data/abstract_class_bench_functional_labels_highrecall.csv\")\n",
        "labeled_df_highrecall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4b6b07a4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CLASSIFICATION METRICS: Functional Experiment Prediction\n",
            "================================================================================\n",
            "\n",
            "True Label: functional_experiment (binary: 0 or 1)\n",
            "Total samples: 1058\n",
            "  Class 0: 529\n",
            "  Class 1: 529\n",
            "\n",
            "================================================================================\n",
            "\n",
            "GPT-4O-MINI\n",
            "--------------------------------------------------------------------------------\n",
            "  Accuracy:           0.7467\n",
            "  Precision (PPV):    0.6878\n",
            "  Recall (Sensitivity): 0.9036\n",
            "  F1 Score:          0.7810\n",
            "  Specificity (TNR): 0.5898\n",
            "  NPV:               0.8595\n",
            "  ROC-AUC:           0.7467\n",
            "  Average Precision: 0.6697\n",
            "\n",
            "  Confusion Matrix:\n",
            "                        Predicted 0     Predicted 1\n",
            "           Actual 0             312             217\n",
            "           Actual 1              51             478\n",
            "\n",
            "  Detailed Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "No Functional Exp     0.8595    0.5898    0.6996       529\n",
            "   Functional Exp     0.6878    0.9036    0.7810       529\n",
            "\n",
            "         accuracy                         0.7467      1058\n",
            "        macro avg     0.7736    0.7467    0.7403      1058\n",
            "     weighted avg     0.7736    0.7467    0.7403      1058\n",
            "\n",
            "\n",
            "O4-MINI\n",
            "--------------------------------------------------------------------------------\n",
            "  Accuracy:           0.7665\n",
            "  Precision (PPV):    0.7156\n",
            "  Recall (Sensitivity): 0.8847\n",
            "  F1 Score:          0.7912\n",
            "  Specificity (TNR): 0.6484\n",
            "  NPV:               0.8490\n",
            "  ROC-AUC:           0.7665\n",
            "  Average Precision: 0.6907\n",
            "\n",
            "  Confusion Matrix:\n",
            "                        Predicted 0     Predicted 1\n",
            "           Actual 0             343             186\n",
            "           Actual 1              61             468\n",
            "\n",
            "  Detailed Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "No Functional Exp     0.8490    0.6484    0.7353       529\n",
            "   Functional Exp     0.7156    0.8847    0.7912       529\n",
            "\n",
            "         accuracy                         0.7665      1058\n",
            "        macro avg     0.7823    0.7665    0.7632      1058\n",
            "     weighted avg     0.7823    0.7665    0.7632      1058\n",
            "\n",
            "\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'gpt-4o-mini': {'Accuracy': 0.7466918714555766,\n",
              "  'Precision (PPV)': 0.6877697841726619,\n",
              "  'Recall (Sensitivity)': 0.9035916824196597,\n",
              "  'F1 Score': 0.7810457516339869,\n",
              "  'Specificity (TNR)': 0.5897920604914934,\n",
              "  'NPV': 0.859504132231405,\n",
              "  'ROC-AUC': 0.7466918714555766,\n",
              "  'Average Precision': 0.669667215188152,\n",
              "  'True Positives (TP)': 478,\n",
              "  'True Negatives (TN)': 312,\n",
              "  'False Positives (FP)': 217,\n",
              "  'False Negatives (FN)': 51,\n",
              "  'Confusion Matrix': array([[312, 217],\n",
              "         [ 51, 478]])},\n",
              " 'o4-mini': {'Accuracy': 0.7665406427221172,\n",
              "  'Precision (PPV)': 0.7155963302752294,\n",
              "  'Recall (Sensitivity)': 0.8846880907372401,\n",
              "  'F1 Score': 0.7912087912087912,\n",
              "  'Specificity (TNR)': 0.6483931947069943,\n",
              "  'NPV': 0.849009900990099,\n",
              "  'ROC-AUC': 0.7665406427221172,\n",
              "  'Average Precision': 0.6907355058011482,\n",
              "  'True Positives (TP)': 468,\n",
              "  'True Negatives (TN)': 343,\n",
              "  'False Positives (FP)': 186,\n",
              "  'False Negatives (FN)': 61,\n",
              "  'Confusion Matrix': array([[343, 186],\n",
              "         [ 61, 468]])}}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, \n",
        "    roc_auc_score, average_precision_score\n",
        ")\n",
        "\n",
        "def calculate_classification_metrics(\n",
        "    df: pd.DataFrame,\n",
        "    true_label_col: str,\n",
        "    model_predictions: dict,\n",
        "    task_name: str = \"Classification Task\",\n",
        "    class_names: tuple = None,\n",
        "    print_results: bool = True\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Calculate classification metrics for multiple models.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame containing true labels and predictions\n",
        "    true_label_col : str\n",
        "        Column name for true labels\n",
        "    model_predictions : dict\n",
        "        Dictionary mapping model names to prediction column names\n",
        "        e.g., {'model1': 'model1_pred_col', 'model2': 'model2_pred_col'}\n",
        "    task_name : str\n",
        "        Name of the classification task (for display purposes)\n",
        "    class_names : tuple, optional\n",
        "        Tuple of class names for display (e.g., ('Class 0', 'Class 1'))\n",
        "        If None, will use generic names\n",
        "    print_results : bool\n",
        "        Whether to print formatted results\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary mapping model names to their metrics dictionaries\n",
        "    \"\"\"\n",
        "    # Remove rows with missing true labels or predictions\n",
        "    required_cols = [true_label_col] + list(model_predictions.values())\n",
        "    df_clean = df.dropna(subset=required_cols).copy()\n",
        "    \n",
        "    if len(df_clean) == 0:\n",
        "        raise ValueError(\"No valid rows after removing missing values\")\n",
        "    \n",
        "    # True labels\n",
        "    y_true = df_clean[true_label_col].values\n",
        "    \n",
        "    # Get predictions for each model\n",
        "    model_preds = {}\n",
        "    for model_name, pred_col in model_predictions.items():\n",
        "        model_preds[model_name] = df_clean[pred_col].values\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for model_name, y_pred in model_preds.items():\n",
        "        # Basic metrics\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "        \n",
        "        # Additional metrics\n",
        "        try:\n",
        "            roc_auc = roc_auc_score(y_true, y_pred)\n",
        "        except ValueError:\n",
        "            roc_auc = None\n",
        "        \n",
        "        try:\n",
        "            avg_precision = average_precision_score(y_true, y_pred)\n",
        "        except ValueError:\n",
        "            avg_precision = None\n",
        "        \n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        \n",
        "        # Additional derived metrics\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        sensitivity = recall  # Same as recall\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative Predictive Value\n",
        "        ppv = precision  # Positive Predictive Value (same as precision)\n",
        "        \n",
        "        results[model_name] = {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision (PPV)': precision,\n",
        "            'Recall (Sensitivity)': recall,\n",
        "            'F1 Score': f1,\n",
        "            'Specificity (TNR)': specificity,\n",
        "            'NPV': npv,\n",
        "            'ROC-AUC': roc_auc,\n",
        "            'Average Precision': avg_precision,\n",
        "            'True Positives (TP)': tp,\n",
        "            'True Negatives (TN)': tn,\n",
        "            'False Positives (FP)': fp,\n",
        "            'False Negatives (FN)': fn,\n",
        "            'Confusion Matrix': cm\n",
        "        }\n",
        "    \n",
        "    if print_results:\n",
        "        # Display results in a nice format\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"CLASSIFICATION METRICS: {task_name}\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\nTrue Label: {true_label_col} (binary: 0 or 1)\")\n",
        "        print(f\"Total samples: {len(df_clean)}\")\n",
        "        print(f\"  Class 0: {(y_true == 0).sum()}\")\n",
        "        print(f\"  Class 1: {(y_true == 1).sum()}\")\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        \n",
        "        for model_name, metrics in results.items():\n",
        "            print(f\"\\n{model_name.upper()}\")\n",
        "            print(\"-\" * 80)\n",
        "            \n",
        "            # Main metrics\n",
        "            print(f\"  Accuracy:           {metrics['Accuracy']:.4f}\")\n",
        "            print(f\"  Precision (PPV):    {metrics['Precision (PPV)']:.4f}\")\n",
        "            print(f\"  Recall (Sensitivity): {metrics['Recall (Sensitivity)']:.4f}\")\n",
        "            print(f\"  F1 Score:          {metrics['F1 Score']:.4f}\")\n",
        "            print(f\"  Specificity (TNR): {metrics['Specificity (TNR)']:.4f}\")\n",
        "            print(f\"  NPV:               {metrics['NPV']:.4f}\")\n",
        "            \n",
        "            if metrics['ROC-AUC'] is not None:\n",
        "                print(f\"  ROC-AUC:           {metrics['ROC-AUC']:.4f}\")\n",
        "            if metrics['Average Precision'] is not None:\n",
        "                print(f\"  Average Precision: {metrics['Average Precision']:.4f}\")\n",
        "            \n",
        "            # Confusion matrix\n",
        "            print(f\"\\n  Confusion Matrix:\")\n",
        "            print(f\"    {'':>15} {'Predicted 0':>15} {'Predicted 1':>15}\")\n",
        "            print(f\"    {'Actual 0':>15} {metrics['True Negatives (TN)']:>15} {metrics['False Positives (FP)']:>15}\")\n",
        "            print(f\"    {'Actual 1':>15} {metrics['False Negatives (FN)']:>15} {metrics['True Positives (TP)']:>15}\")\n",
        "            \n",
        "            # Classification report\n",
        "            target_names = class_names if class_names else ['Class 0', 'Class 1']\n",
        "            print(f\"\\n  Detailed Classification Report:\")\n",
        "            print(classification_report(y_true, model_preds[model_name], target_names=target_names, digits=4))\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Use the function\n",
        "calculate_classification_metrics(\n",
        "    df=labeled_df_highrecall,\n",
        "    true_label_col='functional_experiment',\n",
        "    model_predictions={\n",
        "        'gpt-4o-mini': 'gpt-4o-mini_functional_experiment',\n",
        "        'o4-mini': 'o4-mini_functional_experiment'\n",
        "    },\n",
        "    task_name='Functional Experiment Prediction',\n",
        "    class_names=('No Functional Exp', 'Functional Exp')\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ps3_bs3_llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
