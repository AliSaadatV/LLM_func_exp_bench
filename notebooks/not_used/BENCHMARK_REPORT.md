# LLM PS3/BS3 Functional Evidence Benchmarking Report

## Executive Summary

- **Benchmark Domain:** ACMG/AMP PS3/BS3 functional evidence extraction from scientific literature for clinical variant interpretation.
- **Data Source:** ClinGen-curated variants with PS3/BS3 evidence codes, filtered to 529 variants with available full-text PDFs (466 after variant ID normalization).
- **Models Evaluated:** `gpt-4o-mini` and `o4-mini` (OpenAI API).
- **Tasks:** (1) Binary functional experiment detection from abstracts; (2) PS3/BS3 evidence level classification from full-text PDFs; (3) Evidence strength classification; (4) Joint level+strength classification.
- **Headline Results:** For PS3/BS3 binary classification, `o4-mini` achieved 96.3% accuracy (F1=0.979) compared to `gpt-4o-mini` at 92.6% accuracy (F1=0.960), both with high coverage (>91%). Evidence strength classification proved more challenging, with both models achieving ~34% accuracy on the 4-class strength task.
- **Evaluation Includes:** LLM-as-judge scoring using `gpt-4.1` with majority voting and position-bias mitigation for generated explanation quality.

---

## List of Figures

| Figure # | Title | Artifact Path |
|----------|-------|---------------|
| 1 | Variant Matching Outcomes by Model | `res/figures/variant_matching_outcomes_by_model.png` |
| 2 | PS3/BS3 Classification Metrics Bar Plot | `res/figures/model_ps3_bs3_metrics_barplot.png` |
| 3 | Evidence Strength Metrics Bar Plot | `res/figures/model_strength_metrics_barplot.png` |
| 4 | Joint (Level+Strength) Metrics Bar Plot | `res/figures/model_joint_metrics_barplot.png` |
| 5 | Coverage Vote Scores Violin Plot | `res/figures/coverage_vote_scores_violin.png` |
| 6 | Coverage Vote Confidences Violin Plot | `res/figures/coverage_vote_confidences_violin.png` |

---

## Repository Map

### Core Notebooks (Execution Order)

| Notebook | Purpose | Dependencies |
|----------|---------|--------------|
| `notebooks/01_preprocess_clingen.ipynb` | Data preprocessing: extract PS3/BS3 evidence from ClinGen summaries, fetch abstracts, download PDFs | `data/clingen_curated_variants.txt` |
| `notebooks/02_abstract_class_bench.ipynb` | Abstract-level binary classification benchmark (functional experiment detection) | `data/ps3_bs3_df_processed.csv`, `data/cgbench_pubmed_id_to_text.csv` |
| `notebooks/03_full_text_class_bench.ipynb` | Full-text PDF classification benchmark (PS3/BS3 level, strength), variant matching, LLM judge evaluation | `data/ps3_bs3_df_processed_withVariantIDs.csv`, `res/pdfs/` |

### Supporting Code

| File | Purpose |
|------|---------|
| `src/variant_id_convertor.py` | Variant annotation via VariantValidator with rsID fallback via Ensembl VEP |
| `src/utils.py` | Utility function for formatting variant data into prompt strings |

### Data Files (Inputs)

| File | Description |
|------|-------------|
| `data/clingen_curated_variants.txt` | Tab-separated ClinGen curated variants with ACMG/AMP evidence codes |
| `data/cgbench_pubmed_id_to_text.csv` | PubMed abstracts for negative sampling |

### Data Files (Outputs)

| File | Description | Generated By |
|------|-------------|--------------|
| `data/ps3_bs3_df_processed.csv` | Processed ClinGen data with extracted PMIDs, abstracts, evidence levels | Notebook 01 |
| `data/ps3_bs3_df_processed_withVariantIDs.csv` | Data enriched with standardized variant identifiers | Notebook 03 |
| `data/ps3_bs3_df_processed_withVariantIDs_llmClassifier.tsv` | LLM classification results (raw) | Notebook 03 |
| `data/ps3_bs3_df_processed_withVariantIDs_llmClassifier_llmJudgeScored.csv` | Final results with LLM judge scores | Notebook 03 |
| `data/abstract_class_bench_functional_labels.csv` | Abstract classification results (standard prompt) | Notebook 02 |
| `data/abstract_class_bench_functional_labels_highrecall.csv` | Abstract classification results (high-recall prompt) | Notebook 02 |

### Exploratory (Not Used)

| File | Description |
|------|-------------|
| `notebooks/not_used/00_visualizations.ipynb` | Exploratory visualizations of evidence code distributions |

---

## 3. Benchmark Setup (Methods)

### 3.1 Tasks and Datasets

#### Task 1: Functional Experiment Detection (Abstract-Level)

**Objective:** Binary classification to determine whether a PubMed abstract reports variant-level functional evidence.

**Data Source:**
- **Positive class:** 529 abstracts from ClinGen-curated variants with PS3/BS3 evidence codes and available PDFs
- **Negative class:** 529 abstracts sampled from `cgbench_pubmed_id_to_text.csv` that do not overlap with PS3/BS3 PMIDs

**Filtering Pipeline:**
1. Filter ClinGen variants to those with "PS3" or "BS3" in `Applied Evidence Codes (Met)` column
2. Extract PMIDs from `Summary of interpretation` field using LLM (GPT-4.1-mini)
3. Fetch abstracts via metapub PubMedFetcher
4. Retain only PMIDs with available PDFs in `res/pdfs/`
5. Remove duplicates and missing abstracts

**Reference:** `notebooks/01_preprocess_clingen.ipynb` — Cell 2–3; `notebooks/02_abstract_class_bench.ipynb` — Cell 2–8

**Final Dataset Size:** 1,058 abstracts (529 positive, 529 negative)

#### Task 2: PS3/BS3 Evidence Level Classification (Full-Text)

**Objective:** Classify whether a variant shows PS3 (functionally abnormal), BS3 (functionally normal), or not_clear evidence from full-text PDFs.

**Data Source:**
- 466 variant-paper pairs after removing variants that could not be normalized via VariantValidator
- Ground truth: ClinGen expert-curated PS3/BS3 level (collapsed from `PS3_strong`, `PS3_moderate`, `PS3_supporting`, `BS3_strong`, etc.)

**Reference:** `notebooks/03_full_text_class_bench.ipynb` — Cell 2–6

#### Task 3: Evidence Strength Classification (Full-Text)

**Objective:** 4-class classification of evidence strength: `supporting`, `moderate`, `strong`, `very_strong`

**Ground Truth Processing:**
- Missing strength values default to `strong`
- Normalization: `Strong` → `strong`, `Moderate` → `moderate`, `VeryStrong` → `very_strong`, `P` → `supporting`, `Supporting` → `supporting`

**Reference:** `notebooks/03_full_text_class_bench.ipynb` — Cell 26

#### Task 4: Joint Level+Strength Classification (Full-Text)

**Objective:** 8-class classification combining level (PS3/BS3) × strength (4 levels)

**Reference:** `notebooks/03_full_text_class_bench.ipynb` — Cell 32

---

### 3.2 Models / Baselines

| Model Identifier | Provider | Role | Inference Method |
|------------------|----------|------|------------------|
| `gpt-4o-mini` | OpenAI | Primary classifier | Structured outputs via `client.responses.parse()` / `client.responses.create()` |
| `o4-mini` | OpenAI | Primary classifier | Structured outputs with `reasoning: {"effort": "low"}` |
| `gpt-4.1` | OpenAI | LLM Judge | Text generation for coverage scoring |
| `gpt-4.1-mini` | OpenAI | Preprocessing | Evidence extraction from ClinGen summaries |

**Reference:** Model names defined in:
- `notebooks/01_preprocess_clingen.ipynb` — Cell 2: `OPENAI_MODEL = "gpt-4.1-mini"`
- `notebooks/02_abstract_class_bench.ipynb` — Cell 9: `models=("o4-mini", "gpt-4o-mini")`
- `notebooks/03_full_text_class_bench.ipynb` — Cell 10: `models = ['gpt-4o-mini', 'o4-mini']`
- `notebooks/03_full_text_class_bench.ipynb` — Cell 35: `JUDGE_MODEL = "gpt-4.1"`

---

### 3.3 Prompts

#### 3.3.1 Abstract Classification Prompt (Standard)

**Source:** `notebooks/02_abstract_class_bench.ipynb` — Cell 9 (variable `SYSTEM_STEP1`)

```text
You are a clinical variant interpretation curator.

Task: Decide ONLY whether the abstract reports experimental functional evidence about the effect of one or more genetic variants ("variant/mutation/allele/mutant") on gene product function (such as protein or RNA).

Return functional_experiment=1 if the abstract includes BOTH:
A) Variant-level subject:
   - One or more specific variants are tested OR the abstract clearly studies "patient mutations / mutant constructs / alleles" of the gene (even if the exact variant notation is not listed in the abstract).
AND
B) Experimental functional readout + result:
   - The abstract reports a measured experimental outcome for those variants (abnormal OR normal) relevant to gene/protein/RNA function or a disease-relevant functional pathway/output.

Count as functional_experiment=1 if results are reported from ANY of the following experimental evidence types:

1) Protein / biochemical function (in vitro or in cells):
   - Enzymatic activity, catalytic rate, substrate turnover
   - Binding/interaction, complex formation
   - Protein stability/half-life, folding, degradation
   - Localization/trafficking/secretion, channel transport, receptor signaling
   - Post-translational modification effects when tied to function

2) Cell-based functional consequences:
   - Reporter/pathway output, downstream signaling, electrophysiology
   - Rescue/complementation assays (WT rescues; mutant fails to rescue)
   - Cellular phenotypes tied to mechanism (e.g., DNA repair capacity, metabolic flux, viability under specific stress) with variant-specific comparison

3) RNA-level functional assays (treat as functional evidence when tied to variant effect):
   - Splicing assays (patient RNA/cDNA, RT-PCR, minigene) showing exon skipping/intron retention/aberrant transcripts
   - mRNA stability / nonsense-mediated decay (NMD) evidence attributable to the variant
   - Translation efficiency / processing when experimentally measured
(These are explicitly discussed as informative functional approaches at the mRNA level.) 

4) Model systems (cellular or organismal) WITH variant-level manipulation:
   - Knock-in / engineered variant models, variant-specific phenotypes, or variant-specific functional rescue.

5) Patient-derived material (allow as functional evidence when variant attribution is plausible):
   - Functional readouts measured in patient cells/tissue (e.g., enzyme activity, pathway output, electrophysiology, splicing defects),
     especially when the abstract indicates homozygosity or clearly links the functional result to the variant(s).
(Note: patient-derived assays can reflect broader genetic background, but they can still constitute functional evidence in an abstract-level screen.) 

Important screening rule (to reduce false negatives):
- Do NOT require the abstract to list the exact variant IDs. If it clearly reports functional testing/results for "mutations/variants" in the gene, count it.

Do NOT count as functional_experiment=0 if the abstract is ONLY:
- In silico/computational predictions with no wet-lab assay.
- Pure genetic association, linkage, segregation, case series, phenotype description without a functional readout.
- Gene/pathway biology studies (KO/overexpression/mechanistic work) that do NOT test patient variants / mutant constructs.
- Omics/expression profiling alone (RNA-seq, "gene expression changes") without linking the result to a tested variant's effect on RNA/protein (exceptions: explicit NMD/mRNA stability or variant-driven splicing outcomes).

Tie-breaker:
- If you see any explicit wet-lab assay + a stated result about variants/mutations (even broadly described), return 1.

Return only: functional_experiment (0 or 1).
```

#### 3.3.2 Abstract Classification Prompt (High-Recall Variant)

**Source:** `notebooks/02_abstract_class_bench.ipynb` — Cell 13 (variable `SYSTEM_STEP1`)

The high-recall variant includes additional bias-to-1 instructions:

```text
[...header similar to standard prompt...]

Bias / sensitivity requirement (important)
This screen is intentionally high-sensitivity. If there is reasonable doubt, classify as 1 so the paper can be reviewed downstream.
Default to 1 whenever BOTH (i) variant/mutant language and (ii) any wet-lab functional assay signal are present, even if details are sparse.

[...additional tie-breaker rules...]

Strong "bias-to-1" tie-breakers
Return 1 if ANY of the following patterns appear:
- ("mutation/variant/mutant/allele") + a wet-lab assay keyword (activity, assay, measured, functional, reporter, localization, stability, splicing, RT-PCR, minigene, NMD, electrophysiology, rescue)
- The abstract claims functional impact for mutations ("mutations impair function", "variants reduce activity", "mutants show defective splicing"), even without numbers.

Return functional_experiment = 0 ONLY when it is clearly NOT functional variant testing:
[...exclusion criteria...]

Final rule
If you can point to (A) any variant/mutant subject AND (B) any wet-lab functional readout with an outcome claim, output 1. Otherwise output 0.
```

#### 3.3.3 Full-Text PDF Classification Prompt

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 8 (variable `SYSTEM_STEP2_PDF`)

This is a long, detailed prompt (approximately 350 lines). Key sections:

```text
You are a clinical variant functional-evidence extractor for ACMG/AMP guidelines PS3/BS3 criteria.

INPUTS
- TARGET_VARIANT: gene + identifiers (any of rsID, HGVSg, chr_pos_ref_alt,
  HGVSc, HGVSp, aliases).
- PAPER: a full PDF (may include many variants).

GOAL
- Find all plausible variant-level functional experiments that might correspond to the TARGET_VARIANT. Read all PDF (text, tables, figure captions, and figure panels/embedded labels)
- Be SENSITIVE: when in doubt, extract and clearly mark uncertainty.
- Do NOT hallucinate data.

OUTPUT
- Return ONLY valid JSON that matches the schema exactly.
- Use double quotes for all keys and strings.
- No commentary outside JSON.

────────────────────────────────────
1. VARIANT MATCHING (SOFT GATE)
────────────────────────────────────
Build an equivalents set for the TARGET_VARIANT (without inventing mappings):
- Same rsID
- Same genomic coordinates (exact chr:pos:ref:alt or HGVSg as given)
- Same cDNA change (c.notation; allow formatting variants)
- Same protein change (same ref AA, same position, same alt AA;
  allow 1-letter ↔ 3-letter and formatting variants)

[...Match tiers: STRICT MATCH, SINGLE VARIANT STUDY, HEURISTIC MATCH, NO PLAUSIBLE VARIANT...]

────────────────────────────────────
2. EXPERIMENT EXTRACTION
────────────────────────────────────
Extract experiments ONLY for the variant(s) linked to the TARGET_VARIANT by
your chosen status (matched / single_variant_study_matching / heuristic_matching).

[...detailed extraction rules...]

────────────────────────────────────
3. PS3 / BS3 / not_clear
────────────────────────────────────
Definitions:
- PS3: Variant shows a functionally abnormal result (for example vs. a normal comparator),
consistent with a damaging effect and disease mechanism.
- BS3: Variant shows functionally normal result (for example vs. a normal comparator).
- not_clear: unclear direction, conflicting or insufficient information.

Strength (very_strong / strong / moderate / supporting / not_clear):
- supporting: comparator present + basic controls described (WT ± positive/null) but limited validation
- moderate: well-established assay with clear controls/replication and/or multiple validation controls described
- strong/very_strong: the paper provides rigorous clinical validation/calibration supporting high confidence
  (e.g., multiple known benign/pathogenic controls with clear thresholds or explicit calibration).

If evidence_level = "not_clear":
- evidence_strength MUST be "not_clear".
```

**User Template:**
```text
TARGET_VARIANT: {target_variant_string}

Attached: 1 full-text PDF paper.

Follow the system instructions to:
- Match the TARGET_VARIANT to variant labels in the paper,
- Extract all plausible variant-level functional experiments for that variant,
- Summarize PS3/BS3 evidence and strength.

Return ONLY valid JSON that matches the schema exactly.
Do NOT add any text outside the JSON object.
```

#### 3.3.4 LLM Judge Prompt (Coverage Scoring)

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 35 (variable `PROMPT_COVERAGE_AB`)

```text
You are an impartial scientific judge. Your task is to rigorously determine how well two explanations
refer to the same underlying evidence/experiment and make compatible conclusions about it.

Focus on CONTENT, not wording:
- One explanation may be much more terse than the other.
- Extra correct detail is OK and should not be penalized.
- Penalize contradictions, different experiments, or meaningfully different conclusions.

Avoid position bias: do not prefer A or B due to order.

Score correspondence on a 1–5 Likert scale:
1 = Not the same evidence / contradicts / mostly unrelated
2 = Some overlap but key evidence/conclusions differ or many important misses
3 = Same general evidence but incomplete, vague, or partially mismatched
4 = Same evidence and compatible conclusions; minor omissions OK
5 = Same evidence and conclusions; highly consistent; extra correct detail OK

Return JSON ONLY with:
- score (integer 1–5)
- confidence (0–100)
- rationale (<= 40 words; cite the key reason: same experiment? contradiction? missing key result?)

Explanation A:
{A}

Explanation B:
{B}
```

---

### 3.4 Inference Parameters

#### Abstract Classification

**Source:** `notebooks/02_abstract_class_bench.ipynb` — Cell 9

| Parameter | Value | Notes |
|-----------|-------|-------|
| API Method | `client.responses.parse()` | Structured outputs |
| Temperature | Not specified | Default (likely 1.0 or model default) |
| Reasoning effort | `"low"` | For `o4-mini` only |
| Max retries | 4 | Via tenacity `@retry` decorator |
| Wait strategy | Exponential backoff | min=1, max=20 seconds |
| Output schema | Pydantic `Step1FunctionalExperiment` | `functional_experiment: Literal[0, 1]` |

#### Full-Text Classification

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 9

| Parameter | Value | Notes |
|-----------|-------|-------|
| API Method | `client.responses.create()` | With JSON schema |
| Temperature | Not specified | Default |
| PDF upload | `purpose="assistants"` | PDFs uploaded once, reused |
| JSON Schema | `VARIANT_FUNCTIONAL_SCHEMA` | Strict mode enabled |
| Store | `False` | Results not stored on OpenAI |

#### LLM Judge

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 35

| Parameter | Value | Notes |
|-----------|-------|-------|
| Model | `gpt-4.1` | |
| Temperature | 1.0 | Explicitly set |
| Votes per sample | 5 (default 3 used) | Majority voting |
| Position swap | Yes | A/B order swapped for bias mitigation |

---

### 3.5 Experimental Design

| Aspect | Value | Reference |
|--------|-------|-----------|
| Random seed for negative sampling | 42 | `notebooks/02_abstract_class_bench.ipynb` — Cell 7 |
| Seed for LLM judge voting | Deterministic hash from input strings | Cell 35 (`_stable_seed()`) |
| Number of folds/splits | None (single train-free evaluation) | — |
| Hyperparameter tuning | None | — |
| Ablations | Two prompt variants for abstract classification (standard vs. high-recall) | Cells 9 vs. 13 |

---

### 3.6 Evaluation Protocol

#### Metrics Definitions

All metrics computed using scikit-learn functions.

**Reference:** `notebooks/02_abstract_class_bench.ipynb` — Cell 11; `notebooks/03_full_text_class_bench.ipynb` — Cells 23, 29, 32

| Metric | Implementation | Formula/Notes |
|--------|----------------|---------------|
| Accuracy | `sklearn.metrics.accuracy_score` | (TP + TN) / (TP + TN + FP + FN) |
| Precision (PPV) | `sklearn.metrics.precision_score` | TP / (TP + FP); `zero_division=0` |
| Recall (Sensitivity) | `sklearn.metrics.recall_score` | TP / (TP + FN); `zero_division=0` |
| F1 Score | `sklearn.metrics.f1_score` | 2 × (Precision × Recall) / (Precision + Recall) |
| Specificity (TNR) | `tn / (tn + fp)` | Manual computation |
| NPV | `tn / (tn + fn)` | Manual computation |
| ROC-AUC | `sklearn.metrics.roc_auc_score` | Binary predictions (less informative) |
| Average Precision | `sklearn.metrics.average_precision_score` | Binary predictions |
| Coverage | `n_decided / n_total` | Fraction of non-abstained predictions |

#### Abstention Handling

For full-text classification:
- **Abstention criteria:** Prediction is `not_clear` for level OR strength
- **Coverage:** Reported separately from conditional metrics
- **Conditional metrics:** Computed only on rows where model made a PS3/BS3 decision

**Reference:** `notebooks/03_full_text_class_bench.ipynb` — Cell 23 (function `evaluate_by_model_with_abstentions`)

#### Multiclass Metrics (Strength and Joint Classification)

- Macro averaging across classes
- One-vs-Rest (OVR) metrics per class
- Weighted averaging by class support

**Reference:** `notebooks/03_full_text_class_bench.ipynb` — Cell 29 (function `evaluate_strength_by_model_with_abstentions`)

---

### 3.7 Reproducibility

#### Environment Setup

**Source:** `requirements.yml`

```yaml
name: ai
channels:
  - conda-forge
channel_priority: strict
dependencies:
  - python=3.12
  - pandas
  - requests
  - jupyterlab
  - pip
  - python-dotenv
  - matplotlib
  - urllib3
  - pip:
      - openai
      - metapub
```

**Additional implicit dependencies (inferred from imports):**
- `pydantic`
- `tenacity`
- `tqdm`
- `seaborn`
- `scikit-learn`
- `numpy`

#### Required Environment Variables

Create a `.env` file with:
```
OPENAI_API_KEY=<your-key>
NCBI_API_KEY=<your-key>
NCBI_EMAIL=<your-email>
```

#### Execution Order

1. **Notebook 01:** `notebooks/01_preprocess_clingen.ipynb`
   - Input: `data/clingen_curated_variants.txt`
   - Output: `data/ps3_bs3_df_processed.csv`, `res/pdfs/*.pdf`
   - Runtime: ~Several hours (depends on PDF download availability)

2. **Notebook 02:** `notebooks/02_abstract_class_bench.ipynb`
   - Input: `data/ps3_bs3_df_processed.csv`, `data/cgbench_pubmed_id_to_text.csv`
   - Output: `data/abstract_class_bench_functional_labels.csv`, `data/abstract_class_bench_functional_labels_highrecall.csv`
   - Runtime: ~30 minutes per model (1058 samples × 2 models)

3. **Notebook 03:** `notebooks/03_full_text_class_bench.ipynb`
   - Input: `data/ps3_bs3_df_processed.csv`, `res/pdfs/`
   - Output: `data/ps3_bs3_df_processed_withVariantIDs_llmClassifier_llmJudgeScored.csv`, `res/figures/*.png`
   - Runtime: ~7 hours for classification + ~3 hours for LLM judge (as per notebook outputs)

---

## 4. Results

### 4.1 Main Benchmark Tables

#### Table 1. Abstract-Level Functional Experiment Classification (Standard Prompt)

**Source:** `notebooks/02_abstract_class_bench.ipynb` — Cell 11 output

| Model | Accuracy | Precision | Recall | F1 | Specificity | NPV | ROC-AUC | Avg Precision |
|-------|----------|-----------|--------|-----|-------------|-----|---------|---------------|
| gpt-4o-mini | 0.7429 | 0.6854 | 0.8979 | 0.7774 | 0.5879 | 0.8521 | 0.7429 | 0.6665 |
| o4-mini | 0.7637 | 0.7123 | 0.8847 | 0.7892 | 0.6427 | 0.8479 | 0.7637 | 0.6878 |

**Confusion Matrices:**

gpt-4o-mini:
|  | Predicted 0 | Predicted 1 |
|--|-------------|-------------|
| Actual 0 | 311 | 218 |
| Actual 1 | 54 | 475 |

o4-mini:
|  | Predicted 0 | Predicted 1 |
|--|-------------|-------------|
| Actual 0 | 340 | 189 |
| Actual 1 | 61 | 468 |

**Dataset:** 1,058 samples (529 positive, 529 negative)

**Provenance:**
- Notebook: `notebooks/02_abstract_class_bench.ipynb` — section: Cell 11 — cell: `calculate_classification_metrics` call
- Artifact: `data/abstract_class_bench_functional_labels.csv`

---

#### Table 2. Abstract-Level Functional Experiment Classification (High-Recall Prompt)

**Source:** `notebooks/02_abstract_class_bench.ipynb` — Cell 15 output

| Model | Accuracy | Precision | Recall | F1 | Specificity | NPV | ROC-AUC | Avg Precision |
|-------|----------|-----------|--------|-----|-------------|-----|---------|---------------|
| gpt-4o-mini | 0.7467 | 0.6878 | 0.9036 | 0.7810 | 0.5898 | 0.8595 | 0.7467 | 0.6697 |
| o4-mini | 0.7665 | 0.7156 | 0.8847 | 0.7912 | 0.6484 | 0.8490 | 0.7665 | 0.6907 |

**Provenance:**
- Notebook: `notebooks/02_abstract_class_bench.ipynb` — section: Cell 15 — cell: `calculate_classification_metrics` call
- Artifact: `data/abstract_class_bench_functional_labels_highrecall.csv`

---

#### Table 3. Full-Text PS3/BS3 Level Classification

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 23 output

| Model | n_total | n_decided | Coverage | Accuracy | Precision | Recall | F1 | Specificity | NPV | ROC-AUC |
|-------|---------|-----------|----------|----------|-----------|--------|-----|-------------|-----|---------|
| gpt-4o-mini | 339 | 337 | 0.9941 | 0.9258 | 0.9315 | 0.9901 | 0.9599 | 0.3714 | 0.8125 | 0.6807 |
| o4-mini | 323 | 296 | 0.9164 | 0.9628 | 0.9812 | 0.9775 | 0.9794 | 0.8276 | 0.8000 | 0.9026 |

**Confusion Matrices:**

gpt-4o-mini (positive=PS3):
|  | Predicted BS3 | Predicted PS3 |
|--|---------------|---------------|
| Actual BS3 | 13 | 22 |
| Actual PS3 | 3 | 299 |

o4-mini (positive=PS3):
|  | Predicted BS3 | Predicted PS3 |
|--|---------------|---------------|
| Actual BS3 | 24 | 5 |
| Actual PS3 | 6 | 261 |

**Notes:**
- Metrics computed conditional on model making a PS3 or BS3 decision (excluding `not_clear`)
- `o4-mini` has lower coverage (91.6%) but substantially higher specificity (82.8% vs 37.1%)

**Provenance:**
- Notebook: `notebooks/03_full_text_class_bench.ipynb` — section: Cell 23 — cell: `evaluate_by_model_with_abstentions` call
- Artifact: `data/ps3_bs3_df_processed_withVariantIDs_llmClassifier_llmJudgeScored.csv`

---

#### Table 4. Full-Text Evidence Strength Classification (4-class)

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 29 output

| Model | n_total | n_decided | Coverage | Accuracy | Precision (macro) | Recall (macro) | F1 (macro) | Specificity (macro) |
|-------|---------|-----------|----------|----------|-------------------|----------------|------------|---------------------|
| gpt-4o-mini | 339 | 337 | 0.9941 | 0.3591 | 0.2363 | 0.2555 | 0.1766 | 0.7520 |
| o4-mini | 323 | 296 | 0.9164 | 0.3378 | 0.4318 | 0.2802 | 0.2115 | 0.7654 |

**Classes:** `supporting`, `moderate`, `strong`, `very_strong`

**Provenance:**
- Notebook: `notebooks/03_full_text_class_bench.ipynb` — section: Cell 29 — cell: `evaluate_strength_by_model_with_abstentions` call

---

#### Table 5. Full-Text Joint (Level+Strength) Classification (8-class)

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 32 output

| Model | n_total | n_decided | Coverage | Accuracy | Precision (macro) | Recall (macro) | F1 (macro) |
|-------|---------|-----------|----------|----------|-------------------|----------------|------------|
| gpt-4o-mini | 339 | 337 | 0.9941 | 0.3353 | 0.2068 | 0.1947 | 0.1473 |
| o4-mini | 323 | 296 | 0.9164 | 0.3209 | 0.3181 | 0.2915 | 0.2022 |

**Classes:** `BS3_supporting`, `BS3_moderate`, `BS3_strong`, `BS3_very_strong`, `PS3_supporting`, `PS3_moderate`, `PS3_strong`, `PS3_very_strong`

**Provenance:**
- Notebook: `notebooks/03_full_text_class_bench.ipynb` — section: Cell 32 — cell: `evaluate_joint_level_strength_by_model_with_abstentions` call

---

#### Table 6. Variant Matching Outcomes

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 19 output

| Variant Match Status | gpt-4o-mini | o4-mini |
|---------------------|-------------|---------|
| matched | 283 | 278 |
| heuristic_matching | 56 | 42 |
| single_variant_study_matching | 0 | 3 |
| variant_matching_unsuccessful | 121 | 137 |
| NA (program error) | 3 | 3 |

**Total per model:** 463

**Provenance:**
- Notebook: `notebooks/03_full_text_class_bench.ipynb` — section: Cell 19–20
- Figure: `res/figures/variant_matching_outcomes_by_model.png`

---

### 4.2 Secondary Analyses

#### Ablation: Standard vs. High-Recall Prompts (Abstract Classification)

The high-recall prompt variant showed marginal improvements:

| Model | Prompt | Accuracy | Recall | F1 |
|-------|--------|----------|--------|-----|
| gpt-4o-mini | Standard | 0.7429 | 0.8979 | 0.7774 |
| gpt-4o-mini | High-Recall | 0.7467 | 0.9036 | 0.7810 |
| o4-mini | Standard | 0.7637 | 0.8847 | 0.7892 |
| o4-mini | High-Recall | 0.7665 | 0.8847 | 0.7912 |

**Observation:** The high-recall prompt slightly improved recall for `gpt-4o-mini` (+0.6%) with minimal accuracy change. Effect on `o4-mini` was negligible.

#### LLM Judge Scores (Coverage Quality)

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 39

The LLM judge (`gpt-4.1`) scored how well model-generated explanations matched ClinGen expert curations on a 1–5 Likert scale.

**Methodology:**
- 5 votes per sample with majority voting
- Position bias mitigation via A/B swapping
- Temperature = 1.0

**Provenance:**
- Artifact: `data/ps3_bs3_df_processed_withVariantIDs_llmClassifier_llmJudgeScored.csv` (columns: `_coverage_score`, `_coverage_vote_scores`, etc.)
- Figures: `res/figures/coverage_vote_scores_violin.png`, `res/figures/coverage_vote_confidences_violin.png`

---

### 4.3 Efficiency

| Metric | gpt-4o-mini | o4-mini | Notes |
|--------|-------------|---------|-------|
| Full-text classification runtime | ~2h 55min | ~4h 9min | 463 samples each |
| Avg time per sample (full-text) | ~22.6 sec | ~32.2 sec | From notebook output |
| LLM judge runtime | ~2h 50min | (same samples) | 662 samples total |

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 10 output, Cell 36 output

**Cost/Memory/Throughput:** Not specified in the repository.

---

### 4.4 Qualitative / Error Analysis

**Not specified.** The repository does not include explicit error analysis cells or failure case documentation.

---

## 5. Figures

### Figure 1. Variant Matching Outcomes by Model

**Placeholder:** (insert figure here)

**Generated by:** `notebooks/03_full_text_class_bench.ipynb` — section: Cell 20 — cell: stacked bar plot of `summary_table`

**Artifact path:** `res/figures/variant_matching_outcomes_by_model.png` (and `.pdf`)

**What it shows:** Stacked bar chart comparing the distribution of variant matching outcomes (matched, heuristic_matching, single_variant_study_matching, variant_matching_unsuccessful, NA) between `gpt-4o-mini` and `o4-mini`.

**Notes:** Total counts annotated above each bar (463 per model).

---

### Figure 2. PS3/BS3 Classification Metrics Bar Plot

**Placeholder:** (insert figure here)

**Generated by:** `notebooks/03_full_text_class_bench.ipynb` — section: Cell 24 — cell: grouped bar plot

**Artifact path:** `res/figures/model_ps3_bs3_metrics_barplot.png` (and `.pdf`)

**What it shows:** Grouped bar chart comparing coverage, accuracy, precision, recall, F1, and specificity for PS3/BS3 binary classification between models.

**Notes:** Metrics conditional on PS3/BS3 decision (excludes abstentions).

---

### Figure 3. Evidence Strength Metrics Bar Plot

**Placeholder:** (insert figure here)

**Generated by:** `notebooks/03_full_text_class_bench.ipynb` — section: Cell 30 — cell: grouped bar plot

**Artifact path:** `res/figures/model_strength_metrics_barplot.png` (and `.pdf`)

**What it shows:** Grouped bar chart comparing coverage, accuracy, precision (macro), recall (macro), F1 (macro), and specificity (macro) for 4-class strength classification.

**Notes:** Metrics use macro averaging across strength classes.

---

### Figure 4. Joint (Level+Strength) Metrics Bar Plot

**Placeholder:** (insert figure here)

**Generated by:** `notebooks/03_full_text_class_bench.ipynb` — section: Cell 33 — cell: grouped bar plot

**Artifact path:** `res/figures/model_joint_metrics_barplot.png` (and `.pdf`)

**What it shows:** Grouped bar chart comparing metrics for 8-class joint (level × strength) classification.

**Notes:** Metrics use macro averaging across all 8 classes.

---

### Figure 5. LLM Judge Coverage Vote Scores (Violin Plot)

**Placeholder:** (insert figure here)

**Generated by:** `notebooks/03_full_text_class_bench.ipynb` — section: Cell 39 — cell: `_violinplot_by_model` for scores

**Artifact path:** `res/figures/coverage_vote_scores_violin.png` (and `.pdf`)

**What it shows:** Violin plot of individual LLM judge vote scores (1–5 Likert scale) for each model, showing distribution of coverage quality scores.

**Notes:** Each sample has up to 10 votes (5 base + 5 position-swapped).

---

### Figure 6. LLM Judge Coverage Vote Confidences (Violin Plot)

**Placeholder:** (insert figure here)

**Generated by:** `notebooks/03_full_text_class_bench.ipynb` — section: Cell 39 — cell: `_violinplot_by_model` for confidences

**Artifact path:** `res/figures/coverage_vote_confidences_violin.png` (and `.pdf`)

**What it shows:** Violin plot of LLM judge confidence scores (0–100) for each model.

**Notes:** Confidence represents judge's self-reported certainty in its coverage score.

---

## 6. Provenance & Traceability

### Key Result → Source Mapping

| Result | Notebook | Section/Cell | Artifact |
|--------|----------|--------------|----------|
| Abstract classification (standard) | `02_abstract_class_bench.ipynb` | Cell 11 | `data/abstract_class_bench_functional_labels.csv` |
| Abstract classification (high-recall) | `02_abstract_class_bench.ipynb` | Cell 15 | `data/abstract_class_bench_functional_labels_highrecall.csv` |
| PS3/BS3 level classification | `03_full_text_class_bench.ipynb` | Cell 23 | `data/ps3_bs3_df_processed_withVariantIDs_llmClassifier_llmJudgeScored.csv` |
| Strength classification | `03_full_text_class_bench.ipynb` | Cell 29 | Same as above |
| Joint classification | `03_full_text_class_bench.ipynb` | Cell 32 | Same as above |
| Variant matching counts | `03_full_text_class_bench.ipynb` | Cell 19 | Same as above |
| LLM judge scores | `03_full_text_class_bench.ipynb` | Cell 36–39 | Same as above |

---

## 7. Limitations / Gaps in the Repo

1. **No explicit random seeds for LLM calls:** While negative sampling uses `random_state=42`, LLM API calls do not set seeds (OpenAI API does not guarantee reproducibility without explicit seed parameter).

2. **Missing dependencies in requirements.yml:** `pydantic`, `tenacity`, `tqdm`, `seaborn`, `scikit-learn` are used but not listed in `requirements.yml`.

3. **Temperature not specified for classifiers:** The classification prompts do not explicitly set temperature; behavior depends on API defaults.

4. **No confidence intervals or statistical tests:** Results are point estimates without uncertainty quantification.

5. **Single run:** All evaluations appear to be single runs without repeated trials to assess variance.

6. **LLM judge scores not fully analyzed:** While vote distributions are visualized, no aggregate statistics (mean, median) are reported in the notebook outputs for judge scores.

7. **Ground truth label quality undocumented:** The reliability of ClinGen expert curations as ground truth is assumed but not validated.

8. **Variant matching failures:** 121–137 variants (26–30%) could not be matched by either model, representing potential data quality issues or difficult cases.

9. **Class imbalance in full-text evaluation:** The PS3/BS3 ratio in the matched subset is heavily skewed toward PS3 (302 PS3 vs 35 BS3 for gpt-4o-mini), which may inflate PS3 recall metrics.

10. **Missing error analysis:** No systematic analysis of failure modes or misclassification patterns.

---

## 8. Appendix

### A. Output Schema for Full-Text Classification

**Source:** `notebooks/03_full_text_class_bench.ipynb` — Cell 8 (variable `VARIANT_FUNCTIONAL_SCHEMA`)

The JSON schema enforces strict structure with the following top-level keys:
- `target_variant_input`: string
- `variant_match`: object with `status`, `confidence`, `match_type`, `matched_strings_in_paper`, `equivalents_used`, `where_in_paper`, `notes`
- `experiments`: array of experiment objects
- `overall_evidence`: object with `evidence_level`, `evidence_strength`, `odds_path`, `validation_basis`, `basis`
- `summary`: string

Each experiment object includes: `assay`, `system`, `variant_material`, `readout`, `normal_comparator`, `result` (with `direction` and `effect_size_and_stats`), `controls_and_validation`, `authors_conclusion`, `where_in_paper`, `caveats`, `paper_variant_label`, `variant_link_confidence`.

### B. Pydantic Models for Abstract Classification

**Source:** `notebooks/02_abstract_class_bench.ipynb` — Cell 9

```python
class Step1FunctionalExperiment(BaseModel):
    functional_experiment: Literal[0, 1] = Field(
        ..., 
        description="1 if a functional experiment is reported in the abstract, else 0."
    )

Criterion = Literal["PS3", "BS3", "not_clear"]
Strength = Literal["very_strong", "strong", "moderate", "supporting", "not_clear"]

class Step2ACMGPS3BS3(BaseModel):
    criterion: Criterion = Field(
        ..., 
        description="PS3 if damaging effect; BS3 if no damaging effect; not_clear if unclear."
    )
    strength: Strength = Field(
        ..., 
        description="very_strong/strong/moderate/supporting; not_clear if cannot be determined from abstract."
    )
```

### C. Variant Identifier Format

**Source:** `src/utils.py` — function `format_variant_for_prompt`

Variants are formatted as comma-separated key-value pairs:
```
Gene: {gene_symbol}, chr_pos_ref_alt (hg38): {chr_pos_ref_alt}, chr_pos_ref_alt (hg37): {chr_pos_ref_alt}, HGVSg (hg38): g.{position}, HGVSg (hg37): g.{position}, rsID: {rsid}, HGVSc: {cdna_change}, HGVSp (3-letter): {protein_3letter}, HGVSp (1-letter): {protein_1letter}
```

### D. Evidence Level/Strength Mappings

**Ground truth normalization (from ClinGen):**

| Original | Normalized |
|----------|------------|
| PS3 | PS3 (level) + strong (strength) |
| PS3_P | PS3 + supporting |
| PS3_Moderate | PS3 + moderate |
| PS3_Supporting | PS3 + supporting |
| PS3_VeryStrong | PS3 + very_strong |
| PS3_Strong | PS3 + strong |
| BS3 | BS3 (level) + strong (strength) |
| (similar for BS3 variants) | ... |

**Source:** `notebooks/02_abstract_class_bench.ipynb` — Cell 5; `notebooks/03_full_text_class_bench.ipynb` — Cell 26

---

*Report generated from repository analysis. All metrics, prompts, and configurations are extracted directly from notebook cells and code files as documented above.*
